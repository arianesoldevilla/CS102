"","title","author","subject","abstract","meta"
"1","The Art of Staying Ahead of Deadlines: Improved Algorithms for the Minimum Tardy Processing Time","Mihail Stoian","Data Structures and Algorithms (cs.DS)","We study the fundamental scheduling problem $1\|\sum p_jU_j$. Given a set of $n$ jobs with processing times $p_j$ and deadlines $d_j$, the problem is to select a subset of jobs such that the total processing time is maximized without violating the deadlines. In the midst of a flourishing line of research, Fischer and Wennmann have recently devised the sought-after $\widetilde O(P)$-time algorithm, where $P = \sum p_j$ is the total processing time of all jobs. This running time is optimal as it matches conditional lower bounds based on popular conjectures. However, $P$ is not the sole parameter one could parameterize the running time by. Indeed, they explicitly leave open the question of whether a running time of $\widetilde O(n + \max d_j)$ or even $\widetilde O(n + \max p_j)$ is possible. In this work, we show, somewhat surprisingly, that by a refined implementation of their original algorithm, one can obtain the asked-for $\widetilde O(n + \max d_j)$-time algorithm.","Mon, 26 Feb 2024 18:59:35 UTC (14 KB)"
"2","The Complexity of Diameter on H-free graphs","Jelle J. Oostveen, Daniël Paulusma, Erik Jan van Leeuwen","Data Structures and Algorithms (cs.DS)","The intensively studied Diameter problem is to find the diameter of a given connected graph. We investigate, for the first time in a structured manner, the complexity of Diameter for H-free graphs, that is, graphs that do not contain a fixed graph H as an induced subgraph. We first show that if H is not a linear forest with small components, then Diameter cannot be solved in subquadratic time for H-free graphs under SETH. For some small linear forests, we do show linear-time algorithms for solving Diameter. For other linear forests H, we make progress towards linear-time algorithms by considering specific diameter values. If H is a linear forest, the maximum value of the diameter of any graph in a connected H-free graph class is some constant dmax dependent only on H. We give linear-time algorithms for deciding if a connected H-free graph has diameter dmax, for several linear forests H. In contrast, for one such linear forest H, Diameter cannot be solved in subquadratic time for H-free graphs under SETH. Moreover, we even show that, for several other linear forests H, one cannot decide in subquadratic time if a connected H-free graph has diameter dmax under SETH.","Mon, 26 Feb 2024 15:54:01 UTC (287 KB)"
"3","The structure is the message: preserving experimental context through tensor decomposition","Zhixin Cyrillus Tan, Aaron S. Meyer","Quantitative Methods (q-bio.QM)","Recent biological studies have been revolutionized in scale and granularity by multiplex and high-throughput assays. Profiling cell responses across several experimental parameters, such as perturbations, time, and genetic contexts, leads to richer and more generalizable findings. However, these multidimensional datasets necessitate a reevaluation of the conventional methods for their representation and analysis. Traditionally, experimental parameters are merged to flatten the data into a two-dimensional matrix, sacrificing crucial experiment context reflected by the structure. As Marshall McLuhan famously stated, ""The medium is the message."" In this work, we propose that the experiment structure is the medium in which subsequent analysis is performed, and the optimal choice of data representation must reflect the experiment structure. We introduce tensor-structured analyses and decompositions to preserve this information. We contend that tensor methods are poised to become integral to the biomedical data sciences toolkit.","Mon, 26 Feb 2024 15:09:17 UTC (457 KB)"
"4","The Bottom-Left Algorithm for the Strip Packing Problem","Stefan Hougardy, Bart Zondervan","Data Structures and Algorithms (cs.DS)","The bottom-left algorithm is a simple heuristic for the Strip Packing Problem. It places the rectangles in the given order at the lowest free position in the strip, using the left most position in case of ties. Despite its simplicity, the exact approximation ratio of the bottom-left algorithm remains unknown. We will improve the more-than-40-year-old value for the lower bound from $5/4$ to $4/3 - \varepsilon$. Additionally, we will show that this lower bound holds even in the special case of squares, where the previously known lower bound was $12/11 -\varepsilon$. These lower bounds apply regardless of the ordering of the rectangles. When squares are arranged in the worst possible order, we establish a constant upper bound and a $10/3-\varepsilon$ lower bound for the approximation ratio of the bottom-left algorithm. This bound also applies to some online setting and yields an almost tight result there. Finally, we show that the approximation ratio of a local search algorithm based on permuting rectangles in the ordering of the bottom-left algorithm is at least~$2$ and that such an algorithm may need an exponential number of improvement steps to reach a local optimum.","Mon, 26 Feb 2024 13:49:28 UTC (53 KB)"
"5","A fast implementation of the good-suffix array for the Boyer-Moore string matching algorithm","Thierry Lecroq","Data Structures and Algorithms (cs.DS)","String matching is the problem of finding all the occurrences of a pattern in a text. It has been intensively studied and the Boyer-Moore string matching algorithm is probably one of the most famous solution to this problem. This algorithm uses two precomputed shift tables called the good-suffix table and the bad-character table. The good-suffix table is tricky to compute in linear time. Text book solutions perform redundant operations. Here we present a fast implementation for this good-suffix table based on a tight analysis of the pattern. Experimental results show two versions of this new implementation are the fastest in almost all tested situations.","Mon, 26 Feb 2024 10:29:35 UTC (50 KB)"
"6","Parameterized and approximation algorithms for coverings points with segments in the plane","Katarzyna Kowalska, Michał Pilipczuk","Computational Geometry (cs.CG)","We study parameterized and approximation algorithms for a variant of Set Cover, where the universe of elements to be covered consists of points in the plane and the sets with which the points should be covered are segments. We call this problem Segment Set Cover. We also consider a relaxation of the problem called $\delta$-extension, where we need to cover the points by segments that are extended by a tiny fraction, but we compare the solution's quality to the optimum without extension. For the unparameterized variant, we prove that Segment Set Cover does not admit a PTAS unless $\mathsf{P}=\mathsf{NP}$, even if we restrict segments to be axis-parallel and allow $\frac{1}{2}$-extension. On the other hand, we show that parameterization helps for the tractability of Segment Set Cover: we give an FPT algorithm for unweighted Segment Set Cover parameterized by the solution size $k$, a parameterized approximation scheme for Weighted Segment Set Cover with $k$ being the parameter, and an FPT algorithm for Weighted Segment Set Cover with $\delta$-extension parameterized by $k$ and $\delta$. In the last two results, relaxing the problem is probably necessary: we prove that Weighted Segment Set Cover without any relaxation is $\mathsf{W}[1]$-hard and, assuming ETH, there does not exist an algorithm running in time $f(k)\cdot n^{o(k / \log k)}$. This holds even if one restricts attention to axis-parallel segments.","Mon, 26 Feb 2024 10:17:28 UTC (726 KB)"
"7","An optimal tradeoff between entanglement and copy complexity for state tomography","Sitan Chen, Jerry Li, Allen Liu","Quantum Physics (quant-ph)","There has been significant interest in understanding how practical constraints on contemporary quantum devices impact the complexity of quantum learning. For the classic question of tomography, recent work tightly characterized the copy complexity for any protocol that can only measure one copy of the unknown state at a time, showing it is polynomially worse than if one can make fully-entangled measurements. While we now have a fairly complete picture of the rates for such tasks in the near-term and fault-tolerant regimes, it remains poorly understood what the landscape in between looks like. In this work, we study tomography in the natural setting where one can make measurements of $t$ copies at a time. For sufficiently small $\epsilon$, we show that for any $t \le d^2$, $\widetilde{\Theta}(\frac{d^3}{\sqrt{t}\epsilon^2})$ copies are necessary and sufficient to learn an unknown $d$-dimensional state $\rho$ to trace distance $\epsilon$. This gives a smooth and optimal interpolation between the known rates for single-copy and fully-entangled measurements. To our knowledge, this is the first smooth entanglement-copy tradeoff known for any quantum learning task, and for tomography, no intermediate point on this curve was known, even at $t = 2$. An important obstacle is that unlike the optimal single-copy protocol, the optimal fully-entangled protocol is inherently biased and thus precludes naive batching approaches. Instead, we devise a novel two-stage procedure that uses Keyl's algorithm to refine a crude estimate for $\rho$ based on single-copy measurements. A key insight is to use Schur-Weyl sampling not to estimate the spectrum of $\rho$, but to estimate the deviation of $\rho$ from the maximally mixed state. When $\rho$ is far from the maximally mixed state, we devise a novel quantum splitting procedure that reduces to the case where $\rho$ is close to maximally mixed.","Mon, 26 Feb 2024 07:18:57 UTC (48 KB)"
"8","A Provably Accurate Randomized Sampling Algorithm for Logistic Regression","Agniva Chowdhury, Pradeep Ramuhalli","Machine Learning (stat.ML)","In statistics and machine learning, logistic regression is a widely-used supervised learning technique primarily employed for binary classification tasks. When the number of observations greatly exceeds the number of predictor variables, we present a simple, randomized sampling-based algorithm for logistic regression problem that guarantees high-quality approximations to both the estimated probabilities and the overall discrepancy of the model. Our analysis builds upon two simple structural conditions that boil down to randomized matrix multiplication, a fundamental and well-understood primitive of randomized numerical linear algebra. We analyze the properties of estimated probabilities of logistic regression when leverage scores are used to sample observations, and prove that accurate approximations can be achieved with a sample whose size is much smaller than the total number of observations. To further validate our theoretical findings, we conduct comprehensive empirical evaluations. Overall, our work sheds light on the potential of using randomized sampling approaches to efficiently approximate the estimated probabilities in logistic regression, offering a practical and computationally efficient solution for large-scale datasets.","Mon, 26 Feb 2024 06:20:28 UTC (10,841 KB)"
"9","Algorithms for Halfplane Coverage and Related Problems","Haitao Wang, Jie Xue","Computational Geometry (cs.CG)","Given in the plane a set of points and a set of halfplanes, we consider the problem of computing a smallest subset of halfplanes whose union covers all points. In this paper, we present an $O(n^{4/3}\log^{5/3}n\log^{O(1)}\log n)$-time algorithm for the problem, where $n$ is the total number of all points and halfplanes. This improves the previously best algorithm of $n^{10/3}2^{O(\log^*n)}$ time by roughly a quadratic factor. For the special case where all halfplanes are lower ones, our algorithm runs in $O(n\log n)$ time, which improves the previously best algorithm of $n^{4/3}2^{O(\log^*n)}$ time and matches an $\Omega(n\log n)$ lower bound. Further, our techniques can be extended to solve a star-shaped polygon coverage problem in $O(n\log n)$ time, which in turn leads to an $O(n\log n)$-time algorithm for computing an instance-optimal $\epsilon$-kernel of a set of $n$ points in the plane. Agarwal and Har-Peled presented an $O(nk\log n)$-time algorithm for this problem in SoCG 2023, where $k$ is the size of the $\epsilon$-kernel; they also raised an open question whether the problem can be solved in $O(n\log n)$ time. Our result thus answers the open question affirmatively.","Mon, 26 Feb 2024 06:08:11 UTC (696 KB)"
"10","Problems on Group-labeled Matroid Bases","Florian Hörsch, András Imolay, Ryuhei Mizutani, Taihei Oki, Tamás Schwarcz","Discrete Mathematics (cs.DM)","Consider a matroid equipped with a labeling of its ground set to an abelian group. We define the label of a subset of the ground set as the sum of the labels of its elements. We study a collection of problems on finding bases and common bases of matroids with restrictions on their labels. For zero bases and zero common bases, the results are mostly negative. While finding a non-zero basis of a matroid is not difficult, it turns out that the complexity of finding a non-zero common basis depends on the group. Namely, we show that the problem is hard for a fixed group if it contains an element of order two, otherwise it is polynomially solvable. As a generalization of both zero and non-zero constraints, we further study $F$-avoiding constraints where we seek a basis or common basis whose label is not in a given set $F$ of forbidden labels. Using algebraic techniques, we give a randomized algorithm for finding an $F$-avoiding common basis of two matroids represented over the same field for finite groups given as operation tables. The study of $F$-avoiding bases with groups given as oracles leads to a conjecture stating that whenever an $F$-avoiding basis exists, an $F$-avoiding basis can be obtained from an arbitrary basis by exchanging at most $|F|$ elements. We prove the conjecture for the special cases when $|F|\le 2$ or the group is ordered. By relying on structural observations on matroids representable over fixed, finite fields, we verify a relaxed version of the conjecture for these matroids. As a consequence, we obtain a polynomial-time algorithm in these special cases for finding an $F$-avoiding basis when $|F|$ is fixed.","Mon, 26 Feb 2024 02:44:14 UTC (70 KB)"
"11","Enhanced Graph Pattern Matching","Nicola Cotumaccio","Data Structures and Algorithms (cs.DS)","Pattern matching queries on strings can be solved in linear time by Knuth-Morris-Pratt (KMP) algorithm. In 1973, Weiner introduced the suffix tree of a string [FOCS 1973] and showed that the seemingly more difficult problem of computing matching statistics can also be solved in liner time. Pattern matching queries on graphs are inherently more difficult: under the Orthogonal Vector hypothesis, the graph pattern matching problem cannot be solved in subquadratic time [TALG 2023]. The complexity of graph pattern matching can be parameterized by the topological complexity of the considered graph, which is captured by a parameter $ p $ [JACM 2023]. In this paper, we show that, as in the string setting, computing matching statistics on graph is as difficult as solving standard pattern matching queries. To this end, we introduce a notion of longest common prefix (LCP) array for arbitrary graphs.","Sun, 25 Feb 2024 21:58:52 UTC (47 KB)"
"12","Honeybee: Decentralized Peer Sampling with Verifiable Random Walks for Blockchain Data Sharding","Yunqi Zhang, Shaileshh Bojja Venkatakrishnan","Networking and Internet Architecture (cs.NI)","Data sharding - in which block data is sharded without sharding compute - is at the present the favored approach for scaling Ethereum. A key challenge toward implementing data sharding is verifying whether the entirety of a block's data is available in the network (across its shards). A central technique proposed to conduct this verification uses erasure coded blocks and is called data availability sampling (DAS). While the high-level protocol details of DAS has been well discussed in the community, discussions around how such a protocol will be implemented at the peer-to-peer layer are lacking. We identify random sampling of nodes as a fundamental primitive necessary to carry out DAS and present Honeybee, a decentralized algorithm for sampling node that uses verifiable random walks. Honeybee is secure against attacks even in the presence of a large number of Byzantine nodes (e.g., 50% of the network). We evaluate Honeybee through experiments and show that the quality of sampling achieved by Honeybee is significantly better compared to the state-of-the-art. Our proposed algorithm has implications for DAS functions in both full nodes and light nodes.","Sun, 25 Feb 2024 21:29:44 UTC (1,489 KB)"
"13","Online Drone Scheduling for Last-mile Delivery","Saswata Jana, Giuseppe F. Italiano, Manas Jyoti Kashyop, Athanasios L. Konstantinidis, Evangelos Kosinas, Partha Sarathi Mandal","Data Structures and Algorithms (cs.DS)","Delivering a parcel from the distribution hub to the customer's doorstep is called the \textit{last-mile delivery} step in delivery logistics. In this paper, we study a hybrid {\it truck-drones} model for the last-mile delivery step, in which a truck moves on a predefined path carrying parcels and drones deliver the parcels. We define the \textsc{online drone scheduling} problem, where the truck moves in a predefined path, and the customer's requests appear online during the truck's movement. The objective is to schedule a drone associated with every request to minimize the number of drones used subject to the battery budget of the drones and compatibility of the schedules. We propose a 3-competitive deterministic algorithm using the next-fit strategy and 2.7-competitive algorithms using the first-fit strategy for the problem with $O(\log n)$ worst-case time complexity per request, where $n$ is the maximum number of active requests at any time. We also introduce \textsc{online variable-size drone scheduling} problem (OVDS). Here, we know all the customer's requests in advance; however, the drones with different battery capacities appear online. The objective is to schedule customers' requests for drones to minimize the number of drones used. We propose a $(2\alpha + 1)$-competitive algorithm for the OVDS problem with total running time $O(n \log n)$ for $n$ customer requests, where $\alpha$ is the ratio of the maximum battery capacity to the minimum battery capacity of the drones. Finally, we address how to generate intervals corresponding to each customer request when there are discrete stopping points on the truck's route, from where the drone can fly and meet with the truck.","Sun, 25 Feb 2024 13:20:28 UTC (119 KB)"
"14","List Coloring of some Cayley graphs using Kernel perfections","Prajnanaswaroopa S","Combinatorics (math.CO)","In this paper, we try to determine exact or bounds on the choosability, or list chromatic numbers of some Cayley graphs, typically some Unitary Cayley graphs and Cayley graphs on Dihedral groups.","Sun, 25 Feb 2024 10:06:04 UTC (6 KB)"
"15","Tree decompositions meet induced matchings: beyond Max Weight Independent Set","Paloma T. Lima, Martin Milanič, Peter Muršič, Karolina Okrasa, Paweł Rzążewski, Kenny Štorgel","Data Structures and Algorithms (cs.DS)","For a tree decomposition $\mathcal{T}$ of a graph $G$, by $\mu(\mathcal{T})$ we denote the size of a largest induced matching in $G$ all of whose edges intersect one bag of $\mathcal{T}$. Induced matching treewidth of a graph $G$ is the minimum value of $\mu(\mathcal{T})$ over all tree decompositions $\mathcal{T}$ of $G$. Yolov [SODA 2018] proved that Max Weight Independent Set can be solved in polynomial time for graphs of bounded induced matching treewidth. In this paper we explore what other problems are tractable in such classes of graphs. As our main result, we give a polynomial-time algorithm for Min Weight Feedback Vertex Set. We also provide some positive results concerning packing induced subgraphs, which in particular imply a PTAS for the problem of finding a largest induced subgraph of bounded treewidth. These results suggest that in graphs of bounded induced matching treewidth, one could find in polynomial time a maximum-weight induced subgraph of bounded treewidth satisfying a given CMSO$_2$ formula. We conjecture that such a result indeed holds and prove it for graphs of bounded tree-independence number, which form a rich and important family of subclasses of graphs of bounded induced matching treewidth. We complement these algorithmic results with a number of complexity and structural results concerning induced matching treewidth.","Sat, 24 Feb 2024 15:11:29 UTC (159 KB)"
"16","Pruned Pivot: Correlation Clustering Algorithm for Dynamic, Parallel, and Local Computation Models","Mina Dalirrooyfard, Konstantin Makarychev, Slobodan Mitrović","Data Structures and Algorithms (cs.DS)","Given a graph with positive and negative edge labels, the correlation clustering problem aims to cluster the nodes so to minimize the total number of between-cluster positive and within-cluster negative edges. This problem has many applications in data mining, particularly in unsupervised learning. Inspired by the prevalence of large graphs and constantly changing data in modern applications, we study correlation clustering in dynamic, parallel (MPC), and local computation (LCA) settings. We design an approach that improves state-of-the-art runtime complexities in all these settings. In particular, we provide the first fully dynamic algorithm that runs in an expected amortized constant time, without any dependence on the graph size. Moreover, our algorithm essentially matches the approximation guarantee of the celebrated Pivot algorithm.","Sat, 24 Feb 2024 00:58:50 UTC (89 KB)"
"17","On the Complexity of Community-aware Network Sparsification","Emanuel Herrendorf, Christian Komusiewicz, Nils Morawietz, Frank Sommer","Data Structures and Algorithms (cs.DS)","Network sparsification is the task of reducing the number of edges of a given graph while preserving some crucial graph property. In community-aware network sparsification, the preserved property concerns the subgraphs that are induced by the communities of the graph which are given as vertex subsets. This is formalized in the $\Pi$-Network Sparsification problem: given an edge-weighted graph $G$, a collection $Z$ of $c$ subsets of $V(G)$ (communities), and two numbers $\ell, b$, the question is whether there exists a spanning subgraph $G'$ of $G$ with at most $\ell$ edges of total weight at most $b$ such that $G'[C]$ fulfills $\Pi$ for each community $C$. Here, we consider two graph properties $\Pi$: the connectivity property (Connectivity NWS) and the property of having a spanning star (Stars NWS). Since both problems are NP-hard, we study their parameterized and fine-grained complexity. We provide a tight $2^{\Omega(n^2+c)} poly(n+|Z|)$-time running time lower bound based on the ETH for both problems, where $n$ is the number of vertices in $G$. The lower bound holds even in the restricted case when all communities have size at most 4, $G$ is a clique, and every edge has unit weight. For the connectivity property, the unit weight case with $G$ being a clique is the well-studied problem of computing a hypergraph support with a minimum number of edges. We then study the complexity of both problems parameterized by the feedback edge number $t$ of the solution graph $G'$. For Stars NWS, we present an XP-algorithm for $t$. This answers an open question by Korach and Stern [Disc. Appl. Math. '08] who asked for the existence of polynomial-time algorithms for $t=0$. In contrast, we show for Connectivity NWS that known polynomial-time algorithms for $t=0$ [Korach and Stern, Math. Program. '03; Klemz et al., SWAT '14] cannot be extended by showing that Connectivity NWS is NP-hard for $t=1$.","Fri, 23 Feb 2024 18:32:39 UTC (165 KB)"
"18","Graph Partitioning With Limited Moves","Majid Behbahani, Mina Dalirrooyfard, Elaheh Fata, Yuriy Nevmyvaka","Data Structures and Algorithms (cs.DS)","In many real world networks, there already exists a (not necessarily optimal) $k$-partitioning of the network. Oftentimes, one aims to find a $k$-partitioning with a smaller cut value for such networks by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such real-world applications, we introduce and study the $r$-move $k$-partitioning~problem, a natural variant of the Multiway cut problem. Given a graph, a set of $k$ terminals and an initial partitioning of the graph, the $r$-move $k$-partitioning~problem aims to find a $k$-partitioning with the minimum-weighted cut among all the $k$-partitionings that can be obtained by moving at most $r$ non-terminal nodes to partitions different from their initial ones. Our main result is a polynomial time $3(r+1)$ approximation algorithm for this problem. We further show that this problem is $W[1]$-hard, and give an FPTAS for when $r$ is a small constant.","Fri, 23 Feb 2024 18:25:54 UTC (757 KB)"
"19","Lasso with Latents: Efficient Estimation, Covariate Rescaling, and Computational-Statistical Gaps","Jonathan Kelner, Frederic Koehler, Raghu Meka, Dhruv Rohatgi","Machine Learning (stat.ML)","It is well-known that the statistical performance of Lasso can suffer significantly when the covariates of interest have strong correlations. In particular, the prediction error of Lasso becomes much worse than computationally inefficient alternatives like Best Subset Selection. Due to a large conjectured computational-statistical tradeoff in the problem of sparse linear regression, it may be impossible to close this gap in general. In this work, we propose a natural sparse linear regression setting where strong correlations between covariates arise from unobserved latent variables. In this setting, we analyze the problem caused by strong correlations and design a surprisingly simple fix. While Lasso with standard normalization of covariates fails, there exists a heterogeneous scaling of the covariates with which Lasso will suddenly obtain strong provable guarantees for estimation. Moreover, we design a simple, efficient procedure for computing such a ""smart scaling."" The sample complexity of the resulting ""rescaled Lasso"" algorithm incurs (in the worst case) quadratic dependence on the sparsity of the underlying signal. While this dependence is not information-theoretically necessary, we give evidence that it is optimal among the class of polynomial-time algorithms, via the method of low-degree polynomials. This argument reveals a new connection between sparse linear regression and a special version of sparse PCA with a near-critical negative spike. The latter problem can be thought of as a real-valued analogue of learning a sparse parity. Using it, we also establish the first computational-statistical gap for the closely related problem of learning a Gaussian Graphical Model.","Fri, 23 Feb 2024 16:16:38 UTC (285 KB)"
"20","Tight Approximation and Kernelization Bounds for Vertex-Disjoint Shortest Paths","Matthias Bentert, Fedor V. Fomin, Petr A. Golovach","Data Structures and Algorithms (cs.DS)","We examine the possibility of approximating Maximum Vertex-Disjoint Shortest Paths. In this problem, the input is an edge-weighted (directed or undirected) $n$-vertex graph $G$ along with $k$ terminal pairs $(s_1,t_1),(s_2,t_2),\ldots,(s_k,t_k)$. The task is to connect as many terminal pairs as possible by pairwise vertex-disjoint paths such that each path is a shortest path between the respective terminals. Our work is anchored in the recent breakthrough by Lochet [SODA '21], which demonstrates the polynomial-time solvability of the problem for a fixed value of $k$. Lochet's result implies the existence of a polynomial-time $ck$-approximation for Maximum Vertex-Disjoint Shortest Paths, where $c \leq 1$ is a constant. Our first result suggests that this approximation algorithm is, in a sense, the best we can hope for. More precisely, assuming the gap-ETH, we exclude the existence of an $o(k)$-approximations within $f(k) \cdot $poly($n$) time for any function $f$ that only depends on $k$. Our second result demonstrates the infeasibility of achieving an approximation ratio of $n^{\frac{1}{2}-\varepsilon}$ in polynomial time, unless P = NP. It is not difficult to show that a greedy algorithm selecting a path with the minimum number of arcs results in a $\lceil\sqrt{\ell}\rceil$-approximation, where $\ell$ is the number of edges in all the paths of an optimal solution. Since $\ell \leq n$, this underscores the tightness of the $n^{\frac{1}{2}-\varepsilon}$-inapproximability bound. Additionally, we establish that Maximum Vertex-Disjoint Shortest Paths is fixed-parameter tractable when parameterized by $\ell$ but does not admit a polynomial kernel. Our hardness results hold for undirected graphs with unit weights, while our positive results extend to scenarios where the input graph is directed and features arbitrary (non-negative) edge weights.","Fri, 23 Feb 2024 14:31:52 UTC (25 KB)"
"21","Platforms for Efficient and Incentive-Aware Collaboration","Nika Haghtalab, Mingda Qiao, Kunhe Yang","Computer Science and Game Theory (cs.GT)","Collaboration is crucial for reaching collective goals. However, its effectiveness is often undermined by the strategic behavior of individual agents -- a fact that is captured by a high Price of Stability (PoS) in recent literature [Blum et al., 2021]. Implicit in the traditional PoS analysis is the assumption that agents have full knowledge of how their tasks relate to one another. We offer a new perspective on bringing about efficient collaboration among strategic agents using information design. Inspired by the growing importance of collaboration in machine learning (such as platforms for collaborative federated learning and data cooperatives), we propose a framework where the platform has more information about how the agents' tasks relate to each other than the agents themselves. We characterize how and to what degree such platforms can leverage their information advantage to steer strategic agents toward efficient collaboration. Concretely, we consider collaboration networks where each node is a task type held by one agent, and each task benefits from contributions made in their inclusive neighborhood of tasks. This network structure is known to the agents and the platform, but only the platform knows each agent's real location -- from the agents' perspective, their location is determined by a random permutation. We employ private Bayesian persuasion and design two families of persuasive signaling schemes that the platform can use to ensure a small total workload when agents follow the signal. The first family aims to achieve the minmax optimal approximation ratio compared to the optimal collaboration, which is shown to be $\Theta(\sqrt{n})$ for unit-weight graphs, $\Theta(n^{2/3})$ for graphs with constant minimum edge weights, and $O(n^{3/4})$ for general weighted graphs. The second family ensures per-instance strict improvement compared to full information disclosure.","Fri, 23 Feb 2024 08:04:23 UTC (62 KB)"
"22","Algorithmically Fair Maximization of Multiple Submodular Objective Functions","Georgios Amanatidis, Georgios Birmpas, Philip Lazos, Stefano Leonardi, Rebecca Reiffenhäuser","Data Structures and Algorithms (cs.DS)","Constrained maximization of submodular functions poses a central problem in combinatorial optimization. In many realistic scenarios, a number of agents need to maximize multiple submodular objectives over the same ground set. We study such a setting, where the different solutions must be disjoint, and thus, questions of fairness arise. Inspired from the fair division literature, we suggest a simple round-robin protocol, where agents are allowed to build their solutions one item at a time by taking turns. Unlike what is typical in fair division, however, the prime goal here is to provide a fair algorithmic environment; each agent is allowed to use any algorithm for constructing their respective solutions. We show that just by following simple greedy policies, agents have solid guarantees for both monotone and non-monotone objectives, and for combinatorial constraints as general as $p$-systems (which capture cardinality and matroid intersection constraints). In the monotone case, our results include approximate EF1-type guarantees and their implications in fair division may be of independent interest. Further, although following a greedy policy may not be optimal in general, we show that consistently performing better than that is computationally hard.","Fri, 23 Feb 2024 07:37:05 UTC (389 KB)"
"23","The Cost of Parallelizing Boosting","Xin Lyu, Hongxun Wu, Junzhao Yang","Machine Learning (cs.LG)","We study the cost of parallelizing weak-to-strong boosting algorithms for learning, following the recent work of Karbasi and Larsen. Our main results are two-fold: - First, we prove a tight lower bound, showing that even ""slight"" parallelization of boosting requires an exponential blow-up in the complexity of training. Specifically, let $\gamma$ be the weak learner's advantage over random guessing. The famous \textsc{AdaBoost} algorithm produces an accurate hypothesis by interacting with the weak learner for $\tilde{O}(1 / \gamma^2)$ rounds where each round runs in polynomial time. Karbasi and Larsen showed that ""significant"" parallelization must incur exponential blow-up: Any boosting algorithm either interacts with the weak learner for $\Omega(1 / \gamma)$ rounds or incurs an $\exp(d / \gamma)$ blow-up in the complexity of training, where $d$ is the VC dimension of the hypothesis class. We close the gap by showing that any boosting algorithm either has $\Omega(1 / \gamma^2)$ rounds of interaction or incurs a smaller exponential blow-up of $\exp(d)$. -Complementing our lower bound, we show that there exists a boosting algorithm using $\tilde{O}(1/(t \gamma^2))$ rounds, and only suffer a blow-up of $\exp(d \cdot t^2)$. Plugging in $t = \omega(1)$, this shows that the smaller blow-up in our lower bound is tight. More interestingly, this provides the first trade-off between the parallelism and the total work required for boosting.","Fri, 23 Feb 2024 07:03:52 UTC (25 KB)"
"24","The Umeyama algorithm for matching correlated Gaussian geometric models in the low-dimensional regime","Shuyang Gong, Zhangsong Li","Statistics Theory (math.ST)","Motivated by the problem of matching two correlated random geometric graphs, we study the problem of matching two Gaussian geometric models correlated through a latent node permutation. Specifically, given an unknown permutation $\pi^*$ on $\{1,\ldots,n\}$ and given $n$ i.i.d. pairs of correlated Gaussian vectors $\{X_{\pi^*(i)},Y_i\}$ in $\mathbb{R}^d$ with noise parameter $\sigma$, we consider two types of (correlated) weighted complete graphs with edge weights given by $A_{i,j}=\langle X_i,X_j \rangle$, $B_{i,j}=\langle Y_i,Y_j \rangle$. The goal is to recover the hidden vertex correspondence $\pi^*$ based on the observed matrices $A$ and $B$. For the low-dimensional regime where $d=O(\log n)$, Wang, Wu, Xu, and Yolou [WWXY22+] established the information thresholds for exact and almost exact recovery in matching correlated Gaussian geometric models. They also conducted numerical experiments for the classical Umeyama algorithm. In our work, we prove that this algorithm achieves exact recovery of $\pi^*$ when the noise parameter $\sigma=o(d^{-3}n^{-2/d})$, and almost exact recovery when $\sigma=o(d^{-3}n^{-1/d})$. Our results approach the information thresholds up to a $\operatorname{poly}(d)$ factor in the low-dimensional regime.","Fri, 23 Feb 2024 04:58:54 UTC (32 KB)"
"25","Tight Inapproximability of Target Set Reconfiguration","Naoto Ohsaka","Data Structures and Algorithms (cs.DS)","Given a graph $G$ with a vertex threshold function $\tau$, consider a dynamic process in which any inactive vertex $v$ becomes activated whenever at least $\tau(v)$ of its neighbors are activated. A vertex set $S$ is called a target set if all vertices of $G$ would be activated when initially activating vertices of $S$. In the Minmax Target Set Reconfiguration problem, for a graph $G$ and its two target sets $X$ and $Y$, we wish to transform $X$ into $Y$ by repeatedly adding or removing a single vertex, using only target sets of $G$, so as to minimize the maximum size of any intermediate target set. We prove that it is NP-hard to approximate Minmax Target Set Reconfiguration within a factor of $2-o\left(\frac{1}{\operatorname{polylog} n}\right)$, where $n$ is the number of vertices. Our result establishes a tight lower bound on approximability of Minmax Target Set Reconfiguration, which admits a $2$-factor approximation algorithm. The proof is based on a gap-preserving reduction from Target Set Selection to Minmax Target Set Reconfiguration, where NP-hardness of approximation for the former problem is proven by Chen (SIAM J. Discrete Math., 2009) and Charikar, Naamad, and Wirth (APPROX/RANDOM 2016).","Fri, 23 Feb 2024 03:35:36 UTC (21 KB)"
"26","Repro Samples Method for a Performance Guaranteed Inference in General and Irregular Inference Problems","Minge Xie, Peng Wang","Methodology (stat.ME)","Rapid advancements in data science require us to have fundamentally new frameworks to tackle prevalent but highly non-trivial ""irregular"" inference problems, to which the large sample central limit theorem does not apply. Typical examples are those involving discrete or non-numerical parameters and those involving non-numerical data, etc. In this article, we present an innovative, wide-reaching, and effective approach, called ""repro samples method,"" to conduct statistical inference for these irregular problems plus more. The development relates to but improves several existing simulation-inspired inference approaches, and we provide both exact and approximate theories to support our development. Moreover, the proposed approach is broadly applicable and subsumes the classical Neyman-Pearson framework as a special case. For the often-seen irregular inference problems that involve both discrete/non-numerical and continuous parameters, we propose an effective three-step procedure to make inferences for all parameters. We also develop a unique matching scheme that turns the discreteness of discrete/non-numerical parameters from an obstacle for forming inferential theories into a beneficial attribute for improving computational efficiency. We demonstrate the effectiveness of the proposed general methodology using various examples, including a case study example on a Gaussian mixture model with unknown number of components. This case study example provides a solution to a long-standing open inference question in statistics on how to quantify the estimation uncertainty for the unknown number of components and other associated parameters. Real data and simulation studies, with comparisons to existing approaches, demonstrate the far superior performance of the proposed method.","Thu, 22 Feb 2024 22:43:42 UTC (384 KB)"
"27","Parallel Approximate Maximum Flows in Near-Linear Work and Polylogarithmic Depth","Arpit Agarwal, Sanjeev Khanna, Huan Li, Prathamesh Patil, Chen Wang, Nathan White, Peilin Zhong","Data Structures and Algorithms (cs.DS)","We present a parallel algorithm for the $(1-\epsilon)$-approximate maximum flow problem in capacitated, undirected graphs with $n$ vertices and $m$ edges, achieving $O(\epsilon^{-3}\text{polylog} n)$ depth and $O(m \epsilon^{-3} \text{polylog} n)$ work in the PRAM model. Although near-linear time sequential algorithms for this problem have been known for almost a decade, no parallel algorithms that simultaneously achieved polylogarithmic depth and near-linear work were known. At the heart of our result is a polylogarithmic depth, near-linear work recursive algorithm for computing congestion approximators. Our algorithm involves a recursive step to obtain a low-quality congestion approximator followed by a ""boosting"" step to improve its quality which prevents a multiplicative blow-up in error. Similar to Peng [SODA'16], our boosting step builds upon the hierarchical decomposition scheme of Räcke, Shah, and Täubig [SODA'14]. A direct implementation of this approach, however, leads only to an algorithm with $n^{o(1)}$ depth and $m^{1+o(1)}$ work. To get around this, we introduce a new hierarchical decomposition scheme, in which we only need to solve maximum flows on subgraphs obtained by contracting vertices, as opposed to vertex-induced subgraphs used in Räcke, Shah, and Täubig [SODA'14]. In particular, we are able to directly extract congestion approximators for the subgraphs from a congestion approximator for the entire graph, thereby avoiding additional recursion on those subgraphs. Along the way, we also develop a parallel flow-decomposition algorithm that is crucial to achieving polylogarithmic depth and may be of independent interest.","Thu, 22 Feb 2024 20:23:59 UTC (97 KB)"
"28","Hitting Meets Packing: How Hard Can it Be?","Jacob Focke, Fabian Frei, Shaohua Li, Dániel Marx, Philipp Schepper, Roohani Sharma, Karol Węgrzycki","Data Structures and Algorithms (cs.DS)","We study a general family of problems that form a common generalization of classic hitting (also referred to as covering or transversal) and packing problems. An instance of X-HitPack asks: Can removing k (deletable) vertices of a graph G prevent us from packing $\ell$ vertex-disjoint objects of type X? This problem captures a spectrum of problems with standard hitting and packing on opposite ends. Our main motivating question is whether the combination X-HitPack can be significantly harder than these two base problems. Already for a particular choice of X, this question can be posed for many different complexity notions, leading to a large, so-far unexplored domain in the intersection of the areas of hitting and packing problems. On a high-level, we present two case studies: (1) X being all cycles, and (2) X being all copies of a fixed graph H. In each, we explore the classical complexity, as well as the parameterized complexity with the natural parameters k+l and treewidth. We observe that the combined problem can be drastically harder than the base problems: for cycles or for H being a connected graph with at least 3 vertices, the problem is \Sigma_2^P-complete and requires double-exponential dependence on the treewidth of the graph (assuming the Exponential-Time Hypothesis). In contrast, the combined problem admits qualitatively similar running times as the base problems in some cases, although significant novel ideas are required. For example, for X being all cycles, we establish a 2^poly(k+l)n^O(1) algorithm using an involved branching method. Also, for X being all edges (i.e., H = K_2; this combines Vertex Cover and Maximum Matching) the problem can be solved in time 2^\poly(tw)n^O(1) on graphs of treewidth tw. The key step enabling this running time relies on a combinatorial bound obtained from an algebraic (linear delta-matroid) representation of possible matchings.","Thu, 22 Feb 2024 19:19:52 UTC (417 KB)"
"29","Time Efficient Implementation for Online $k$-server Problem on Trees","Kamil Khadiev, Maxim Yagafarov","Data Structures and Algorithms (cs.DS)","We consider online algorithms for the $k$-server problem on trees of size $n$. Chrobak and Larmore proposed a $k$-competitive algorithm for this problem that has the optimal competitive ratio. However, the existing implementations have $O\left(k^2 + k\cdot \log n\right)$ or $O\left(k(\log n)^2\right)$ time complexity for processing a query, where $n$ is the number of nodes. We propose a new time-efficient implementation of this algorithm that has $O(n)$ time complexity for preprocessing and $O\left(k\log k\right)$ time for processing a query. The new algorithm is faster than both existing algorithms and the time complexity for query processing does not depend on the tree size.","Thu, 22 Feb 2024 15:27:58 UTC (165 KB)"
"30","Approximate Circular Pattern Matching under Edit Distance","Panagiotis Charalampopoulos, Solon P. Pissis, Jakub Radoszewski, Wojciech Rytter, Tomasz Waleń, Wiktor Zuba","Data Structures and Algorithms (cs.DS)","In the $k$-Edit Circular Pattern Matching ($k$-Edit CPM) problem, we are given a length-$n$ text $T$, a length-$m$ pattern $P$, and a positive integer threshold $k$, and we are to report all starting positions of the substrings of $T$ that are at edit distance at most $k$ from some cyclic rotation of $P$. In the decision version of the problem, we are to check if any such substring exists. Very recently, Charalampopoulos et al. [ESA 2022] presented $O(nk^2)$-time and $O(nk \log^3 k)$-time solutions for the reporting and decision versions of $k$-Edit CPM, respectively. Here, we show that the reporting and decision versions of $k$-Edit CPM can be solved in $O(n+(n/m) k^6)$ time and $O(n+(n/m) k^5 \log^3 k)$ time, respectively, thus obtaining the first algorithms with a complexity of the type $O(n+(n/m) \mathrm{poly}(k))$ for this problem. Notably, our algorithms run in $O(n)$ time when $m=\Omega(k^6)$ and are superior to the previous respective solutions when $m=\omega(k^4)$. We provide a meta-algorithm that yields efficient algorithms in several other interesting settings, such as when the strings are given in a compressed form (as straight-line programs), when the strings are dynamic, or when we have a quantum computer. We obtain our solutions by exploiting the structure of approximate circular occurrences of $P$ in $T$, when $T$ is relatively short w.r.t. $P$. Roughly speaking, either the starting positions of approximate occurrences of rotations of $P$ form $O(k^4)$ intervals that can be computed efficiently, or some rotation of $P$ is almost periodic (is at a small edit distance from a string with small period). Dealing with the almost periodic case is the most technically demanding part of this work; we tackle it using properties of locked fragments (originating from [Cole and Hariharan, SICOMP 2002]).","Thu, 22 Feb 2024 13:42:47 UTC (280 KB)"
"31","An Improved Pseudopolynomial Time Algorithm for Subset Sum","Lin Chen, Jiayi Lian, Yuchen Mao, Guochuan Zhang","Data Structures and Algorithms (cs.DS)","We investigate pseudo-polynomial time algorithms for Subset Sum. Given a multi-set $X$ of $n$ positive integers and a target $t$, Subset Sum asks whether some subset of $X$ sums to $t$. Bringmann proposes an $\tilde{O}(n + t)$-time algorithm [Bringmann SODA'17], and an open question has naturally arisen: can Subset Sum be solved in $O(n + w)$ time? Here $w$ is the maximum integer in $X$. We make a progress towards resolving the open question by proposing an $\tilde{O}(n + \sqrt{wt})$-time algorithm.","Thu, 22 Feb 2024 12:38:42 UTC (26 KB)"
"32","Data Science with LLMs and Interpretable Models","Sebastian Bordt, Ben Lengerich, Harsha Nori, Rich Caruana","Machine Learning (cs.LG)","Recent years have seen important advances in the building of interpretable models, machine learning models that are designed to be easily understood by humans. In this work, we show that large language models (LLMs) are remarkably good at working with interpretable models, too. In particular, we show that LLMs can describe, interpret, and debug Generalized Additive Models (GAMs). Combining the flexibility of LLMs with the breadth of statistical patterns accurately described by GAMs enables dataset summarization, question answering, and model critique. LLMs can also improve the interaction between domain experts and interpretable models, and generate hypotheses about the underlying phenomenon. We release \url{this https URL} as an open-source LLM-GAM interface.","Thu, 22 Feb 2024 12:04:15 UTC (427 KB)"
"33","Parameterized Complexity of Finding Dissimilar Shortest Paths","Ryo Funayama, Yasuaki Kobayashi, Takeaki Uno","Data Structures and Algorithms (cs.DS)","We consider the problem of finding ``dissimilar'' $k$ shortest paths from $s$ to $t$ in an edge-weighted directed graph $D$, where the dissimilarity is measured by the minimum pairwise Hamming distances between these paths. More formally, given an edge-weighted directed graph $D = (V, A)$, two specified vertices $s, t \in V$, and integers $d, k$, the goal of Dissimilar Shortest Paths is to decide whether $D$ has $k$ shortest paths $P_1, \dots, P_k$ from $s$ to $t$ such that $|A(P_i) \mathbin{\triangle} A(P_j)| \ge d$ for distinct $P_i$ and $P_j$. We design a deterministic algorithm to solve Dissimilar Shortest Paths with running time $2^{O(3^kdk^2)}n^{O(1)}$, that is, Dissimilar Shortest Paths is fixed-parameter tractable parameterized by $k + d$. To complement this positive result, we show that Dissimilar Shortest Paths is W[1]-hard when parameterized by only $k$ and paraNP-hard parameterized by $d$.","Thu, 22 Feb 2024 08:40:03 UTC (687 KB)"
"34","Extention of Bagging MARS with Group LASSO for Heterogeneous Treatment Effect Estimation","Guanwenqing He, Ke Wan, Kazushi Maruo, Toshio Shimokawa","Methodology (stat.ME)","Recent years, large scale clinical data like patient surveys and medical record data are playing an increasing role in medical data science. These large-scale clinical data, collectively referred to as ""real-world data (RWD)"". It is expected to be widely used in large-scale observational studies of specific diseases, personal medicine or precise medicine, finding the responder of drugs or treatments. Applying RWD for estimating heterogeneous treat ment effect (HTE) has already been a trending topic. HTE has the potential to considerably impact the development of precision medicine by helping doctors make more informed precise treatment decisions and provide more personalized medical care. The statistical models used to estimate HTE is called treatment effect models. Powers et al. proposed a some treatment effect models for observational study, where they pointed out that the bagging causal MARS (BCM) performs outstanding compared to other models. While BCM has excellent performance, it still has room for improvement. In this paper, we proposed a new treatment effect model called shrinkage causal bagging MARS method to improve their shared basis conditional mean regression framework based on the following points: first, we estimated basis functions using transformed outcome, then applied the group LASSO method to optimize the model and estimate parameters. Besides, we are focusing on pursing better interpretability of model to improve the ethical acceptance. We designed simulations to verify the performance of our proposed method and our proposed method superior in mean square error and bias in most simulation settings. Also we applied it to real data set ACTG 175 to verify its usability, where our results are supported by previous studies.","Thu, 22 Feb 2024 04:47:22 UTC (2,962 KB)"
"35","Locality Bounds for Sampling Hamming Slices","Daniel M. Kane, Anthony Ostuni, Kewen Wu","Computational Complexity (cs.CC)","Spurred by the influential work of Viola (Journal of Computing 2012), the past decade has witnessed an active line of research into the complexity of (approximately) sampling distributions, in contrast to the traditional focus on the complexity of computing functions. We build upon and make explicit earlier implicit results of Viola to provide superconstant lower bounds on the locality of Boolean functions approximately sampling the uniform distribution over binary strings of particular Hamming weights, both exactly and modulo an integer, answering questions of Viola (Journal of Computing 2012) and Filmus, Leigh, Riazanov, and Sokolov (RANDOM 2023). Applications to data structure lower bounds and quantum-classical separations are discussed.","Thu, 22 Feb 2024 04:36:49 UTC (416 KB)"
"36","Sample-Efficient Linear Regression with Self-Selection Bias","Jason Gaitonde, Elchanan Mossel","Statistics Theory (math.ST)","We consider the problem of linear regression with self-selection bias in the unknown-index setting, as introduced in recent work by Cherapanamjeri, Daskalakis, Ilyas, and Zampetakis [STOC 2023]. In this model, one observes $m$ i.i.d. samples $(\mathbf{x}_{\ell},z_{\ell})_{\ell=1}^m$ where $z_{\ell}=\max_{i\in [k]}\{\mathbf{x}_{\ell}^T\mathbf{w}_i+\eta_{i,\ell}\}$, but the maximizing index $i_{\ell}$ is unobserved. Here, the $\mathbf{x}_{\ell}$ are assumed to be $\mathcal{N}(0,I_n)$ and the noise distribution $\mathbf{\eta}_{\ell}\sim \mathcal{D}$ is centered and independent of $\mathbf{x}_{\ell}$. We provide a novel and near optimally sample-efficient (in terms of $k$) algorithm to recover $\mathbf{w}_1,\ldots,\mathbf{w}_k\in \mathbb{R}^n$ up to additive $\ell_2$-error $\varepsilon$ with polynomial sample complexity $\tilde{O}(n)\cdot \mathsf{poly}(k,1/\varepsilon)$ and significantly improved time complexity $\mathsf{poly}(n,k,1/\varepsilon)+O(\log(k)/\varepsilon)^{O(k)}$. When $k=O(1)$, our algorithm runs in $\mathsf{poly}(n,1/\varepsilon)$ time, generalizing the polynomial guarantee of an explicit moment matching algorithm of Cherapanamjeri, et al. for $k=2$ and when it is known that $\mathcal{D}=\mathcal{N}(0,I_k)$. Our algorithm succeeds under significantly relaxed noise assumptions, and therefore also succeeds in the related setting of max-linear regression where the added noise is taken outside the maximum. For this problem, our algorithm is efficient in a much larger range of $k$ than the state-of-the-art due to Ghosh, Pananjady, Guntuboyina, and Ramchandran [IEEE Trans. Inf. Theory 2022] for not too small $\varepsilon$, and leads to improved algorithms for any $\varepsilon$ by providing a warm start for existing local convergence methods.","Thu, 22 Feb 2024 02:20:24 UTC (46 KB)"
"37","Random-Order Online Interval Scheduling and Geometric Generalizations","Mohit Garg, Debajyoti Kar, Arindam Khan","Data Structures and Algorithms (cs.DS)","In the Maximum Independent Set of Hyperrectangles problem, we are given a set of $n$ (possibly overlapping) $d$-dimensional axis-aligned hyperrectangles, and the goal is to find a subset of non-overlapping hyperrectangles of maximum cardinality. For $d=1$, this corresponds to the classical Interval Scheduling problem, where a simple greedy algorithm returns an optimal solution. In the offline setting, for $d$-dimensional hyperrectangles, polynomial time $(\log n)^{O(d)}$-approximation algorithms are known. However, the problem becomes notably challenging in the online setting, where the input objects (hyperrectangles) appear one by one in an adversarial order, and on the arrival of an object, the algorithm needs to make an immediate and irrevocable decision whether or not to select the object while maintaining the feasibility. Even for interval scheduling, an $\Omega(n)$ lower bound is known on the competitive ratio. To circumvent these negative results, in this work, we study the online maximum independent set of axis-aligned hyperrectangles in the random-order arrival model, where the adversary specifies the set of input objects which then arrive in a uniformly random order. Starting from the prototypical secretary problem, the random-order model has received significant attention to study algorithms beyond the worst-case competitive analysis. Surprisingly, we show that the problem in the random-order model almost matches the best-known offline approximation guarantees, up to polylogarithmic factors. In particular, we give a simple $(\log n)^{O(d)}$-competitive algorithm for $d$-dimensional hyperrectangles in this model, which runs in $\tilde{O_d}(n)$ time. Our approach also yields $(\log n)^{O(d)}$-competitive algorithms in the random-order model for more general objects such as $d$-dimensional fat objects and ellipsoids.","Thu, 22 Feb 2024 01:04:18 UTC (47 KB)"
"38","Masked Matrix Multiplication for Emergent Sparsity","Brian Wheatman, Meghana Madhyastha, Randal Burns","Data Structures and Algorithms (cs.DS)","Artificial intelligence workloads, especially transformer models, exhibit emergent sparsity in which computations perform selective sparse access to dense data. The workloads are inefficient on hardware designed for dense computations and do not map well onto sparse data representations. We build a vectorized and parallel matrix-multiplication system A X B = C that eliminates unnecessary computations and avoids branches based on a runtime evaluation of sparsity. We use a combination of dynamic code lookup to adapt to the specific sparsity encoded in the B matrix and preprocessing of sparsity maps of the A and B matrices to compute conditional branches once for the whole computation. For a wide range of sparsity, from 60% to 95% zeros, our implementation performs fewer instructions and increases performance when compared with Intel MKL's dense or sparse matrix multiply routines. Benefits can be as large as 2 times speedup and 4 times fewer instructions.","Wed, 21 Feb 2024 20:36:08 UTC (823 KB)"
"39","Probability Tools for Sequential Random Projection","Yingru Li","Statistics Theory (math.ST)","We introduce the first probabilistic framework tailored for sequential random projection, an approach rooted in the challenges of sequential decision-making under uncertainty. The analysis is complicated by the sequential dependence and high-dimensional nature of random variables, a byproduct of the adaptive mechanisms inherent in sequential decision processes. Our work features a novel construction of a stopped process, facilitating the analysis of a sequence of concentration events that are interconnected in a sequential manner. By employing the method of mixtures within a self-normalized process, derived from the stopped process, we achieve a desired non-asymptotic probability bound. This bound represents a non-trivial martingale extension of the Johnson-Lindenstrauss (JL) lemma, marking a pioneering contribution to the literature on random projection and sequential analysis.","Fri, 16 Feb 2024 13:17:13 UTC (21 KB)"
"40","Misalignment, Learning, and Ranking: Harnessing Users Limited Attention","Arpit Agarwal, Rad Niazadeh, Prathamesh Patil","Machine Learning (cs.LG)","In digital health and EdTech, recommendation systems face a significant challenge: users often choose impulsively, in ways that conflict with the platform's long-term payoffs. This misalignment makes it difficult to effectively learn to rank items, as it may hinder exploration of items with greater long-term payoffs. Our paper tackles this issue by utilizing users' limited attention spans. We propose a model where a platform presents items with unknown payoffs to the platform in a ranked list to $T$ users over time. Each user selects an item by first considering a prefix window of these ranked items and then picking the highest preferred item in that window (and the platform observes its payoff for this item). We study the design of online bandit algorithms that obtain vanishing regret against hindsight optimal benchmarks. We first consider adversarial window sizes and stochastic iid payoffs. We design an active-elimination-based algorithm that achieves an optimal instance-dependent regret bound of $O(\log(T))$, by showing matching regret upper and lower bounds. The key idea is using the combinatorial structure of the problem to either obtain a large payoff from each item or to explore by getting a sample from that item. This method systematically narrows down the item choices to enhance learning efficiency and payoff. Second, we consider adversarial payoffs and stochastic iid window sizes. We start from the full-information problem of finding the permutation that maximizes the expected payoff. By a novel combinatorial argument, we characterize the polytope of admissible item selection probabilities by a permutation and show it has a polynomial-size representation. Using this representation, we show how standard algorithms for adversarial online linear optimization in the space of admissible probabilities can be used to obtain a polynomial-time algorithm with $O(\sqrt{T})$ regret.","Wed, 21 Feb 2024 18:52:20 UTC (45 KB)"
"41","Chasing Convex Functions with Long-term Constraints","Adam Lechowicz, Nicolas Christianson, Bo Sun, Noman Bashir, Mohammad Hajiesmaili, Adam Wierman, Prashant Shenoy","Data Structures and Algorithms (cs.DS)","We introduce and study a family of online metric problems with long-term constraints. In these problems, an online player makes decisions $\mathbf{x}_t$ in a metric space $(X,d)$ to simultaneously minimize their hitting cost $f_t(\mathbf{x}_t)$ and switching cost as determined by the metric. Over the time horizon $T$, the player must satisfy a long-term demand constraint $\sum_{t} c(\mathbf{x}_t) \geq 1$, where $c(\mathbf{x}_t)$ denotes the fraction of demand satisfied at time $t$. Such problems can find a wide array of applications to online resource allocation in sustainable energy and computing systems. We devise optimal competitive and learning-augmented algorithms for specific instantiations of these problems, and further show that our proposed algorithms perform well in numerical experiments.","Wed, 21 Feb 2024 18:51:42 UTC (220 KB)"
"42","On Distributed Computation of the Minimum Triangle Edge Transversal","Keren Censor-Hillel, Majd Khoury","Distributed, Parallel, and Cluster Computing (cs.DC)","The distance of a graph from being triangle-free is a fundamental graph parameter, counting the number of edges that need to be removed from a graph in order for it to become triangle-free. Its corresponding computational problem is the classic minimum triangle edge transversal problem, and its normalized value is the baseline for triangle-freeness testing algorithms. While triangle-freeness testing has been successfully studied in the distributed setting, computing the distance itself in a distributed setting is unknown, to the best of our knowledge, despite being well-studied in the centralized setting. This work addresses the computation of the minimum triangle edge transversal in distributed networks. We show with a simple warm-up construction that this is a global task, requiring $\Omega(D)$ rounds even in the $\mathsf{LOCAL}$ model with unbounded messages, where $D$ is the diameter of the network. However, we show that approximating this value can be done much faster. A $(1+\epsilon)$-approximation can be obtained in $\text{poly}\log{n}$ rounds, where $n$ is the size of the network graph. Moreover, faster approximations can be obtained, at the cost of increasing the approximation factor to roughly 3, by a reduction to the minimum hypergraph vertex cover problem. With a time overhead of the maximum degree $\Delta$, this can also be applied to the $\mathsf{CONGEST}$ model, in which messages are bounded. Our key technical contribution is proving that computing an exact solution is ``as hard as it gets'' in $\mathsf{CONGEST}$, requiring a near-quadratic number of rounds. Because this problem is an edge selection problem, as opposed to previous lower bounds that were for node selection problems, major challenges arise in constructing the lower bound, requiring us to develop novel ingredients.","Wed, 21 Feb 2024 18:14:24 UTC (1,145 KB)"
"43","A $(5/3+ε)$-Approximation for Tricolored Non-crossing Euclidean TSP","Júlia Baligács, Yann Disser, Andreas Emil Feldmann, Anna Zych-Pawlewicz","Data Structures and Algorithms (cs.DS)","In the Tricolored Euclidean Traveling Salesperson problem, we are given~$k=3$ sets of points in the plane and are looking for disjoint tours, each covering one of the sets. Arora (1998) famously gave a PTAS based on ``patching'' for the case $k=1$ and, recently, Dross et al.~(2023) generalized this result to~$k=2$. Our contribution is a $(5/3+\epsilon)$-approximation algorithm for~$k=3$ that further generalizes Arora's approach. It is believed that patching is generally no longer possible for more than two tours. We circumvent this issue by either applying a conditional patching scheme for three tours or using an alternative approach based on a weighted solution for $k=2$.","Wed, 21 Feb 2024 17:07:04 UTC (129 KB)"
"44","Robust recovery for stochastic block models, simplified and generalized","Sidhanth Mohanty, Prasad Raghavendra, David X. Wu","Data Structures and Algorithms (cs.DS)","We study the problem of $\textit{robust community recovery}$: efficiently recovering communities in sparse stochastic block models in the presence of adversarial corruptions. In the absence of adversarial corruptions, there are efficient algorithms when the $\textit{signal-to-noise ratio}$ exceeds the $\textit{Kesten--Stigum (KS) threshold}$, widely believed to be the computational threshold for this problem. The question we study is: does the computational threshold for robust community recovery also lie at the KS threshold? We answer this question affirmatively, providing an algorithm for robust community recovery for arbitrary stochastic block models on any constant number of communities, generalizing the work of Ding, d'Orsi, Nasser & Steurer on an efficient algorithm above the KS threshold in the case of $2$-community block models. There are three main ingredients to our work: (i) The Bethe Hessian of the graph is defined as $H_G(t) \triangleq (D_G-I)t^2 - A_Gt + I$ where $D_G$ is the diagonal matrix of degrees and $A_G$ is the adjacency matrix. Empirical work suggested that the Bethe Hessian for the stochastic block model has outlier eigenvectors corresponding to the communities right above the Kesten-Stigum threshold. We formally confirm the existence of outlier eigenvalues for the Bethe Hessian, by explicitly constructing outlier eigenvectors from the community vectors. (ii) We develop an algorithm for a variant of robust PCA on sparse matrices. Specifically, an algorithm to partially recover top eigenspaces from adversarially corrupted sparse matrices under mild delocalization constraints. (iii) A rounding algorithm to turn vector assignments of vertices into a community assignment, inspired by the algorithm of Charikar \& Wirth \cite{CW04} for $2$XOR.","Wed, 21 Feb 2024 16:40:13 UTC (42 KB)"
"45","Practical algorithms for Hierarchical overlap graphs","Saumya Talera, Parth Bansal, Shabnam Khan, Shahbaz Khan","Data Structures and Algorithms (cs.DS)","Genome assembly is a prominent problem studied in bioinformatics, which computes the source string using a set of its overlapping substrings. Classically, genome assembly uses assembly graphs built using this set of substrings to compute the source string efficiently, having a tradeoff between scalability and avoiding information loss. The scalable de Bruijn graphs come at the price of losing crucial overlap information. The complete overlap information is stored in overlap graphs using quadratic space. Hierarchical overlap graphs [IPL20] (HOG) overcome these limitations, avoiding information loss despite using linear space. After a series of suboptimal improvements, Khan and Park et al. simultaneously presented two optimal algorithms [CPM2021], where only the former was seemingly practical. We empirically analyze all the practical algorithms for computing HOG, where the optimal algorithm [CPM2021] outperforms the previous algorithms as expected, though at the expense of extra memory. However, it uses non-intuitive approach and non-trivial data structures. We present arguably the most intuitive algorithm, using only elementary arrays, which is also optimal. Our algorithm empirically proves even better for both time and memory over all the algorithms, highlighting its significance in both theory and practice. We further explore the applications of hierarchical overlap graphs to solve various forms of suffix-prefix queries on a set of strings. Loukides et al. [CPM2023] recently presented state-of-the-art algorithms for these queries. However, these algorithms require complex black-box data structures and are seemingly impractical. Our algorithms, despite failing to match the state-of-the-art algorithms theoretically, answer different queries ranging from 0.01-100 milliseconds for a data set having around a billion characters.","Wed, 21 Feb 2024 16:39:28 UTC (228 KB)"
"46","A Uniformly Random Solution to Algorithmic Redistricting","Jin-Yi Cai, Jacob Kruse, Kenneth Mayer, Daniel P. Szabo","Data Structures and Algorithms (cs.DS)","The process of drawing electoral district boundaries is known as political redistricting. Within this context, gerrymandering is the practice of drawing these boundaries such that they unfairly favor a particular political party, often leading to unequal representation and skewed electoral outcomes. One of the few ways to detect gerrymandering is by algorithmically sampling redistricting plans. Previous methods mainly focus on sampling from some neighborhood of ``realistic' districting plans, rather than a uniform sample of the entire space. We present a deterministic subexponential time algorithm to uniformly sample from the space of all possible $ k $-partitions of a bounded degree planar graph, and with this construct a sample of the entire space of redistricting plans. We also give a way to restrict this sample space to plans that match certain compactness and population constraints at the cost of added complexity. The algorithm runs in $ 2^{O(\sqrt{n}\log n)} $ time, although we only give a heuristic implementation. Our method generalizes an algorithm to count self-avoiding walks on a square to count paths that split general planar graphs into $ k $ regions, and uses this to sample from the space of all $ k $-partitions of a planar graph.","Wed, 21 Feb 2024 15:20:58 UTC (1,603 KB)"
"47","Diversity-Aware $k$-Maximum Inner Product Search Revisited","Qiang Huang, Yanhao Wang, Yiqun Sun, Anthony K. H. Tung","Information Retrieval (cs.IR)","The $k$-Maximum Inner Product Search ($k$MIPS) serves as a foundational component in recommender systems and various data mining tasks. However, while most existing $k$MIPS approaches prioritize the efficient retrieval of highly relevant items for users, they often neglect an equally pivotal facet of search results: \emph{diversity}. To bridge this gap, we revisit and refine the diversity-aware $k$MIPS (D$k$MIPS) problem by incorporating two well-known diversity objectives -- minimizing the average and maximum pairwise item similarities within the results -- into the original relevance objective. This enhancement, inspired by Maximal Marginal Relevance (MMR), offers users a controllable trade-off between relevance and diversity. We introduce \textsc{Greedy} and \textsc{DualGreedy}, two linear scan-based algorithms tailored for D$k$MIPS. They both achieve data-dependent approximations and, when aiming to minimize the average pairwise similarity, \textsc{DualGreedy} attains an approximation ratio of $1/4$ with an additive term for regularization. To further improve query efficiency, we integrate a lightweight Ball-Cone Tree (BC-Tree) index with the two algorithms. Finally, comprehensive experiments on ten real-world data sets demonstrate the efficacy of our proposed methods, showcasing their capability to efficiently deliver diverse and relevant search results to users.","Wed, 21 Feb 2024 15:09:51 UTC (758 KB)"
"48","Multi-Agent Online Graph Exploration on Cycles and Tadpole Graphs","Erik van den Akker, Kevin Buchin, Klaus-Tycho Foerster","Data Structures and Algorithms (cs.DS)","We study the problem of multi-agent online graph exploration, in which a team of k agents has to explore a given graph, starting and ending on the same node. The graph is initially unknown. Whenever a node is visited by an agent, its neighborhood and adjacent edges are revealed. The agents share a global view of the explored parts of the graph. The cost of the exploration has to be minimized, where cost either describes the time needed for the entire exploration (time model), or the length of the longest path traversed by any agent (energy model). We investigate graph exploration on cycles and tadpole graphs for 2-4 agents, providing optimal results on the competitive ratio in the energy model (1-competitive with two agents on cycles and three agents on tadpole graphs), and for tadpole graphs in the time model (1.5-competitive with four agents). We also show competitive upper bounds of 2 for the exploration of tadpole graphs with three agents, and 2.5 for the exploration of tadpole graphs with two agents in the time model.","Wed, 21 Feb 2024 14:43:34 UTC (28 KB)"
"49","Equilibria, Efficiency, and Inequality in Network Formation for Hiring and Opportunity","Cynthia Dwork, Chris Hays, Jon Kleinberg, Manish Raghavan","Computer Science and Game Theory (cs.GT)","Professional networks -- the social networks among people in a given line of work -- can serve as a conduit for job prospects and other opportunities. Here we propose a model for the formation of such networks and the transfer of opportunities within them. In our theoretical model, individuals strategically connect with others to maximize the probability that they receive opportunities from them. We explore how professional networks balance connectivity, where connections facilitate opportunity transfers to those who did not get them from outside sources, and congestion, where some individuals receive too many opportunities from their connections and waste some of them. We show that strategic individuals are over-connected at equilibrium relative to a social optimum, leading to a price of anarchy for which we derive nearly tight asymptotic bounds. We also show that, at equilibrium, individuals form connections to those who provide similar benefit to them as they provide to others. Thus, our model provides a microfoundation in professional networking contexts for the fundamental sociological principle of homophily, that ""similarity breeds connection,"" which in our setting is realized as a form of status homophily based on alignment in individual benefit. We further explore how, even if individuals are a priori equally likely to receive opportunities from outside sources, equilibria can be unequal, and we provide nearly tight bounds on how unequal they can be. Finally, we explore the ability for online platforms to intervene to improve social welfare and show that natural heuristics may result in adverse effects at equilibrium. Our simple model allows for a surprisingly rich analysis of coordination problems in professional networks and suggests many directions for further exploration.","Wed, 21 Feb 2024 14:38:37 UTC (6,769 KB)"
"50","Adaptive Massively Parallel Coloring in Sparse Graphs","Rustam Latypov, Yannic Maus, Shreyas Pai, Jara Uitto","Distributed, Parallel, and Cluster Computing (cs.DC)","Classic symmetry-breaking problems on graphs have gained a lot of attention in models of modern parallel computation. The Adaptive Massively Parallel Computation (AMPC) is a model that captures central challenges in data center computations. Chang et al. [PODC'2019] gave an extremely fast, constant time, algorithm for the $(\Delta + 1)$-coloring problem, where $\Delta$ is the maximum degree of an input graph of $n$ nodes. The algorithm works in the most restrictive low-space setting, where each machine has $n^{\delta}$ local space for a constant $0 < \delta < 1$. In this work, we study the vertex-coloring problem in sparse graphs parameterized by their arboricity $\alpha$, a standard measure for sparsity. We give deterministic algorithms that in constant, or almost constant, time give $\text{poly}(\alpha)$ and $O(\alpha)$-colorings, where $\alpha$ can be arbitrarily smaller than $\Delta$. A strong and standard approach to compute arboricity-dependent colorings is through the Nash-Williams forest decomposition, which gives rise to an (acyclic) orientation of the edges such that each node has a small outdegree. Our main technical contribution is giving efficient deterministic algorithms to compute these orientations and showing how to leverage them to find colorings in low-space AMPC. A key technical challenge is that the color of a node may depend on almost all of the other nodes in the graph and these dependencies cannot be stored on a single machine. Nevertheless, our novel and careful exploration technique yields the orientation, and the arboricity-dependent coloring, with a sublinear number of adaptive queries per node.","Wed, 21 Feb 2024 12:33:34 UTC (451 KB)"
"51","ExaLogLog: Space-Efficient and Practical Approximate Distinct Counting up to the Exa-Scale","Otmar Ertl","Data Structures and Algorithms (cs.DS)","This work introduces ExaLogLog, a new data structure for approximate distinct counting, which has the same practical properties as the popular HyperLogLog algorithm. It is commutative, idempotent, mergeable, reducible, has a constant-time insert operation, and supports distinct counts up to the exa-scale. At the same time, as theoretically derived and experimentally verified, it requires 43% less space to achieve the same estimation error.","Wed, 21 Feb 2024 11:39:33 UTC (7,540 KB)"
"52","Towards Linear Spanners in All Temporal Cliques","Sebastian Angrick, Ben Bals, Tobias Friedrich, Hans Gawendowicz, Niko Hastrich, Nicolas Klodt, Pascal Lenzner, Jonas Schmidt, George Skretas, Armin Wells","Discrete Mathematics (cs.DM)","Many real-world networks, like transportation networks and social networks, are dynamic in the sense that the edge set may change over time, but these changes are known in advance. This behavior is captured by the temporal graphs model, which has recently become a trending topic in theoretical computer science. A core open problem in the field is to prove the existence of linear-size temporal spanners in temporal cliques, i.e., sparse subgraphs of complete temporal graphs that ensure all-pairs reachability via temporal paths. So far, the best known result is the existence of temporal spanners with $\mathcal{O}(n\log n)$ many edges. We present significant progress towards proving that linear-size temporal spanners exist in all temporal cliques. We adapt techniques used in previous works and heavily expand and generalize them to provide a simpler and more intuitive proof of the $\mathcal{O}(n\log n)$ bound. Moreover, we use our novel approach to show that a large class of temporal cliques, called edge-pivot graphs, admit linear-size temporal spanners. To contrast this, we investigate other classes of temporal cliques that do not belong to the class of edge-pivot graphs. We introduce two such graph classes and we develop novel techniques for establishing the existence of linear temporal spanners in these graph classes as well.","Wed, 21 Feb 2024 08:53:04 UTC (453 KB)"
"53","A cutting plane algorithm for globally solving low dimensional k-means clustering problems","Martin Ryner, Jan Kronqvist, Johan Karlsson","Optimization and Control (math.OC)","Clustering is one of the most fundamental tools in data science and machine learning, and k-means clustering is one of the most common such methods. There is a variety of approximate algorithms for the k-means problem, but computing the globally optimal solution is in general NP-hard. In this paper we consider the k-means problem for instances with low dimensional data and formulate it as a structured concave assignment problem. This allows us to exploit the low dimensional structure and solve the problem to global optimality within reasonable time for large data sets with several clusters. The method builds on iteratively solving a small concave problem and a large linear programming problem. This gives a sequence of feasible solutions along with bounds which we show converges to zero optimality gap. The paper combines methods from global optimization theory to accelerate the procedure, and we provide numerical results on their performance.","Wed, 21 Feb 2024 07:55:33 UTC (63 KB)"
"54","Prediction of the Economic Behavior of Fishery Biotechnology Companies Based on Machine Learning-Based Deep Metacellular Automata","Liguo Chen, Hongyang Hua, Xinyue Luo, Guoli Xu, Xu Yan","Applications (stat.AP)","Ocean warming significantly affects the fishing industry, with species like Scottish herring and mackerel migrating northwards. Our research, a fusion of artificial intelligence, data science, and operations research, addresses this crisis. Using Long Short Term Memory networks, we forecast sea surface temperatures (SST) and model fish migratory patterns with Enhanced Cellular Automata. A corrective factor within our model adjusts for human impact on SST, guiding diverse mitigation scenarios. We apply operational research to strategize responses, including the modernization of fishing vessels as a less costly alternative to relocation. Our data-driven approach, suggesting fleet modernization, strategic relocation, and product diversification, offers an effective approach to mitigating the threats to the ocean warming phenomenon.","Wed, 21 Feb 2024 03:43:49 UTC (679 KB)[v2] Sat, 24 Feb 2024 07:12:00 UTC (735 KB)"
"55","Sketching AI Concepts with Capabilities and Examples: AI Innovation in the Intensive Care Unit","Nur Yildirim, Susanna Zlotnikov, Deniz Sayar, Jeremy M. Kahn, Leigh A. Bukowski, Sher Shah Amin, Kathryn A. Riman, Billie S. Davis, John S. Minturn, Andrew J. King, Dan Ricketts, Lu Tang, Venkatesh Sivaraman, Adam Perer, Sarah M. Preum, James McCann, John Zimmerman","Human-Computer Interaction (cs.HC)","Advances in artificial intelligence (AI) have enabled unprecedented capabilities, yet innovation teams struggle when envisioning AI concepts. Data science teams think of innovations users do not want, while domain experts think of innovations that cannot be built. A lack of effective ideation seems to be a breakdown point. How might multidisciplinary teams identify buildable and desirable use cases? This paper presents a first hand account of ideating AI concepts to improve critical care medicine. As a team of data scientists, clinicians, and HCI researchers, we conducted a series of design workshops to explore more effective approaches to AI concept ideation and problem formulation. We detail our process, the challenges we encountered, and practices and artifacts that proved effective. We discuss the research implications for improved collaboration and stakeholder engagement, and discuss the role HCI might play in reducing the high failure rate experienced in AI innovation.","Wed, 21 Feb 2024 00:11:13 UTC (8,166 KB)"
"56","Structured Tree Alignment for Evaluation of (Speech) Constituency Parsing","Freda Shi, Kevin Gimpel, Karen Livescu","Computation and Language (cs.CL)","We present the structured average intersection-over-union ratio (STRUCT-IOU), a similarity metric between constituency parse trees motivated by the problem of evaluating speech parsers. STRUCT-IOU enables comparison between a constituency parse tree (over automatically recognized spoken word boundaries) with the ground-truth parse (over written words). To compute the metric, we project the ground-truth parse tree to the speech domain by forced alignment, align the projected ground-truth constituents with the predicted ones under certain structured constraints, and calculate the average IOU score across all aligned constituent pairs. STRUCT-IOU takes word boundaries into account and overcomes the challenge that the predicted words and ground truth may not have perfect one-to-one correspondence. Extending to the evaluation of text constituency parsing, we demonstrate that STRUCT-IOU shows higher tolerance to syntactically plausible parses than PARSEVAL (Black et al., 1991).","Wed, 21 Feb 2024 00:01:17 UTC (6,835 KB)"
"57","Minimizing Tardy Processing Time on a Single Machine in Near-Linear Time","Nick Fischer, Leo Wennmann","Data Structures and Algorithms (cs.DS)","In this work we revisit the elementary scheduling problem $1||\sum p_j U_j$. The goal is to select, among $n$ jobs with processing times and due dates, a subset of jobs with maximum total processing time that can be scheduled in sequence without violating their due dates. This problem is NP-hard, but a classical algorithm by Lawler and Moore from the 60s solves this problem in pseudo-polynomial time $O(nP)$, where $P$ is the total processing time of all jobs. With the aim to develop best-possible pseudo-polynomial-time algorithms, a recent wave of results has improved Lawler and Moore's algorithm for $1||\sum p_j U_j$: First to time $\tilde O(P^{7/4})$ [Bringmann, Fischer, Hermelin, Shabtay, Wellnitz; ICALP'20], then to time $\tilde O(P^{5/3})$ [Klein, Polak, Rohwedder; SODA'23], and finally to time $\tilde O(P^{7/5})$ [Schieber, Sitaraman; WADS'23]. It remained an exciting open question whether these works can be improved further. In this work we develop an algorithm in near-linear time $\tilde O(P)$ for the $1||\sum p_j U_j$ problem. This running time not only significantly improves upon the previous results, but also matches conditional lower bounds based on the Strong Exponential Time Hypothesis or the Set Cover Hypothesis and is therefore likely optimal (up to subpolynomial factors). Our new algorithm also extends to the case of $m$ machines in time $\tilde O(P^m)$. In contrast to the previous improvements, we take a different, more direct approach inspired by the recent reductions from Modular Subset Sum to dynamic string problems. We thereby arrive at a satisfyingly simple algorithm.","Tue, 20 Feb 2024 20:19:33 UTC (226 KB)"
"58","Online Matching on $3$-Uniform Hypergraphs","Sander Borst, Danish Kashaev, Zhuan Khye Koh","Data Structures and Algorithms (cs.DS)","The online matching problem was introduced by Karp, Vazirani and Vazirani (STOC 1990) on bipartite graphs with vertex arrivals. It is well-known that the optimal competitive ratio is $1-1/e$ for both integral and fractional versions of the problem. Since then, there has been considerable effort to find optimal competitive ratios for other related settings. In this work, we go beyond the graph case and study the online matching problem on $k$-uniform hypergraphs. For $k=3$, we provide an optimal primal-dual fractional algorithm, which achieves a competitive ratio of $(e-1)/(e+1)\approx 0.4621$. As our main technical contribution, we present a carefully constructed adversarial instance, which shows that this ratio is in fact optimal. It combines ideas from known hard instances for bipartite graphs under the edge-arrival and vertex-arrival models. For $k\geq 3$, we give a simple integral algorithm which performs better than greedy when the online nodes have bounded degree. As a corollary, it achieves the optimal competitive ratio of 1/2 on 3-uniform hypergraphs when every online node has degree at most 2. This is because the special case where every online node has degree 1 is equivalent to the edge-arrival model on graphs, for which an upper bound of 1/2 is known.","Tue, 20 Feb 2024 18:41:11 UTC (214 KB)"
"59","Testing Calibration in Subquadratic Time","Lunjia Hu, Kevin Tian, Chutong Yang","Machine Learning (cs.LG)","In the recent literature on machine learning and decision making, calibration has emerged as a desirable and widely-studied statistical property of the outputs of binary prediction models. However, the algorithmic aspects of measuring model calibration have remained relatively less well-explored. Motivated by [BGHN23], which proposed a rigorous framework for measuring distances to calibration, we initiate the algorithmic study of calibration through the lens of property testing. We define the problem of calibration testing from samples where given $n$ draws from a distribution $\mathcal{D}$ on (predictions, binary outcomes), our goal is to distinguish between the case where $\mathcal{D}$ is perfectly calibrated, and the case where $\mathcal{D}$ is $\varepsilon$-far from calibration. We design an algorithm based on approximate linear programming, which solves calibration testing information-theoretically optimally (up to constant factors) in time $O(n^{1.5} \log(n))$. This improves upon state-of-the-art black-box linear program solvers requiring $\Omega(n^\omega)$ time, where $\omega > 2$ is the exponent of matrix multiplication. We also develop algorithms for tolerant variants of our testing problem, and give sample complexity lower bounds for alternative calibration distances to the one considered in this work. Finally, we present preliminary experiments showing that the testing problem we define faithfully captures standard notions of calibration, and that our algorithms scale to accommodate moderate sample sizes.","Tue, 20 Feb 2024 17:53:24 UTC (89 KB)"
"60","Improved Space Bounds for Subset Sum","Tatiana Belova, Nikolai Chukhin, Alexander S. Kulikov, Ivan Mihajlin","Computational Complexity (cs.CC)","More than 40 years ago, Schroeppel and Shamir presented an algorithm that solves the Subset Sum problem for $n$ integers in time $O^*(2^{0.5n})$ and space $O^*(2^{0.25n})$. The time upper bound remains unbeaten, but the space upper bound has been improved to $O^*(2^{0.249999n})$ in a recent breakthrough paper by Nederlof and Węgrzycki (STOC 2021). Their algorithm is a clever combination of a number of previously known techniques with a new reduction and a new algorithm for the Orthogonal Vectors problem. In this paper, we give two new algorithms for Subset Sum. We start by presenting an Arthur--Merlin algorithm: upon receiving the verifier's randomness, the prover sends an $n/4$-bit long proof to the verifier who checks it in (deterministic) time and space $O^*(2^{n/4})$. The simplicity of this algorithm has a number of interesting consequences: it can be parallelized easily; also, by enumerating all possible proofs, one recovers upper bounds on time and space for Subset Sum proved by Schroeppel and Shamir in 1979. As it is the case with the previously known algorithms for Subset Sum, our algorithm follows from an algorithm for $4$-SUM: we prove that, using verifier's coin tosses, the prover can prepare a $\log_2 n$-bit long proof verifiable in time $\tilde{O}(n)$. Another interesting consequence of this result is the following fine-grained lower bound: assuming that $4$-SUM cannot be solved in time $O(n^{2-\varepsilon})$ for all $\varepsilon>0$, Circuit SAT cannot be solved in time $O(g2^{(1-\varepsilon)n})$, for all $\varepsilon>0$. Then, we improve the space bound by Nederlof and Węgrzycki to $O^*(2^{0.246n})$ and also simplify their algorithm and its analysis. We achieve this space bound by further filtering sets of subsets using a random prime number. This allows us to reduce an instance of Subset Sum to a larger number of instances of smaller size.","Tue, 20 Feb 2024 17:30:45 UTC (27 KB)"
"61","Clustered Planarity Variants for Level Graphs","Simon D. Fink, Matthias Pfretzschner, Ignaz Rutter, Marie Diana Sieper","Computational Geometry (cs.CG)","We consider variants of the clustered planarity problem for level-planar drawings. So far, only convex clusters have been studied in this setting. We introduce two new variants that both insist on a level-planar drawing of the input graph but relax the requirements on the shape of the clusters. In unrestricted Clustered Level Planarity (uCLP) we only require that they are bounded by simple closed curves that enclose exactly the vertices of the cluster and cross each edge of the graph at most once. The problem y-monotone Clustered Level Planarity (y-CLP) requires that additionally it must be possible to augment each cluster with edges that do not cross the cluster boundaries so that it becomes connected while the graph remains level-planar, thereby mimicking a classic characterization of clustered planarity in the level-planar setting. We give a polynomial-time algorithm for uCLP if the input graph is biconnected and has a single source. By contrast, we show that y-CLP is hard under the same restrictions and it remains NP-hard even if the number of levels is bounded by a constant and there is only a single non-trivial cluster.","Tue, 20 Feb 2024 17:10:42 UTC (429 KB)"
"62","Almost-Tight Bounds on Preserving Cuts in Classes of Submodular Hypergraphs","Sanjeev Khanna, Aaron L. Putterman, Madhu Sudan","Data Structures and Algorithms (cs.DS)","Recently, a number of variants of the notion of cut-preserving hypergraph sparsification have been studied in the literature. These variants include directed hypergraph sparsification, submodular hypergraph sparsification, general notions of approximation including spectral approximations, and more general notions like sketching that can answer cut queries using more general data structures than just sparsifiers. In this work, we provide reductions between these different variants of hypergraph sparsification and establish new upper and lower bounds on the space complexity of preserving their cuts. At a high level, our results use the same general principle, namely, by showing that cuts in one class of hypergraphs can be simulated by cuts in a simpler class of hypergraphs, we can leverage sparsification results for the simpler class of hypergraphs.","Tue, 20 Feb 2024 17:06:47 UTC (29 KB)"
"63","Deterministic Dynamic Edge-Colouring","Aleksander B. G. Christiansen","Data Structures and Algorithms (cs.DS)","Given a dynamic graph $G$ with $n$ vertices and $m$ edges subject to insertion an deletions of edges, we show how to maintain a $(1+\varepsilon)\Delta$-edge-colouring of $G$ without the use of randomisation. More specifically, we show a deterministic dynamic algorithm with an amortised update time of $2^{\tilde{O}_{\log \varepsilon^{-1}}(\sqrt{\log n})}$ using $(1+\varepsilon)\Delta$ colours. If $\varepsilon^{-1} \in 2^{O(\log^{0.49} n)}$, then our update time is sub-polynomial in $n$. While there exists randomised algorithms maintaining colourings with the same number of colours [Christiansen STOC'23, Duan, He, Zhang SODA'19, Bhattacarya, Costa, Panski, Solomon SODA'24] in polylogarithmic and even constant update time, this is the first deterministic algorithm to go below the greedy threshold of $2\Delta-1$ colours for all input graphs. On the way to our main result, we show how to dynamically maintain a shallow hierarchy of degree-splitters with both recourse and update time in $n^{o(1)}$. We believe that this algorithm might be of independent interest.","Tue, 20 Feb 2024 16:54:43 UTC (642 KB)"
"64","Scalable Pattern Matching in Computation Graphs","Luca Mondada, Pablo Andrés-Martínez","Data Structures and Algorithms (cs.DS)","Graph rewriting is a popular tool for the optimisation and modification of graph expressions in domains such as compilers, machine learning and quantum computing. The underlying data structures are often port graphs - graphs with labels at edge endpoints. These port labels greatly simplify pattern matching. A pre-requisite for graph rewriting is the ability to find subgraphs of the input that match known graph identities: the pattern matching problem. We propose a new solution to pattern matching in port graphs. Its novelty lies in the use of a pre-computed data structure that makes the pattern matching runtime complexity independent of the number of patterns. The runtime is bound by the maximum width $w$ and depth $d$ of the patterns, as well as the input graph size $|G|$ as $O(|G| \cdot c^w / w^{1/2} \cdot d)$ with $c = 6.75$. This offers a significant advantage over existing solutions for use cases where patterns have low width and the set of patterns is large and fixed ahead of time. In the context of quantum circuits, pattern width can be limited to qubit number. Quantum superoptimisers may use thousands of rewrite rules on circuits with less than 5 qubits, making them an ideal use case. We provide benchmarks showing that our algorithm offers a 20x speedup over current implementations on a dataset of 10'000 real world patterns describing quantum circuits.","Tue, 20 Feb 2024 15:02:24 UTC (113 KB)"
"65","Efficient Enumeration of Large Maximal k-Plexes","Qihao Cheng, Da Yan, Tianhao Wu, Lyuheng Yuan, Ji Cheng, Zhongyi Huang, Yang Zhou","Data Structures and Algorithms (cs.DS)","Finding cohesive subgraphs in a large graph has many important applications, such as community detection and biological network analysis. Clique is often a too strict cohesive structure since communities or biological modules rarely form as cliques for various reasons such as data noise. Therefore, $k$-plex is introduced as a popular clique relaxation, which is a graph where every vertex is adjacent to all but at most $k$ vertices. In this paper, we propose an efficient branch-and-bound algorithm as well as its task-based parallel version to enumerate all maximal $k$-plexes with at least $q$ vertices. Our algorithm adopts an effective search space partitioning approach that provides a good time complexity, a new pivot vertex selection method that reduces candidate vertex size, an effective upper-bounding technique to prune useless branches, and three novel pruning techniques by vertex pairs. Our parallel algorithm uses a timeout mechanism to eliminate straggler tasks, and maximizes cache locality while ensuring load balancing. Extensive experiments show that compared with the state-of-the-art algorithms, our sequential and parallel algorithms enumerate large maximal $k$-plexes with up to $5 \times$ and $18.9 \times$ speedup, respectively. Ablation results also demonstrate that our pruning techniques bring up to $7 \times$ speedup compared with our basic algorithm.","Tue, 20 Feb 2024 13:43:16 UTC (680 KB)"
"66","Locally Rainbow Paths","Till Fluschnik, Leon Kellerhals, Malte Renken","Data Structures and Algorithms (cs.DS)","We introduce the algorithmic problem of finding a locally rainbow path of length $\ell$ connecting two distinguished vertices $s$ and $t$ in a vertex-colored directed graph. Herein, a path is locally rainbow if between any two visits of equally colored vertices, the path traverses consecutively at least $r$ differently colored vertices. This problem generalizes the well-known problem of finding a rainbow path. It finds natural applications whenever there are different types of resources that must be protected from overuse, such as crop sequence optimization or production process scheduling. We show that the problem is computationally intractable even if $r=2$ or if one looks for a locally rainbow among the shortest paths. On the positive side, if one looks for a path that takes only a short detour (i.e., it is slightly longer than the shortest path) and if $r$ is small, the problem can be solved efficiently. Indeed, the running time of the respective algorithm is near-optimal unless the ETH fails.","Tue, 20 Feb 2024 10:50:01 UTC (45 KB)"
"67","Differentiable Mapper For Topological Optimization Of Data Representation","Ziyad Oulhaj, Mathieu Carrière, Bertrand Michel","Machine Learning (cs.LG)","Unsupervised data representation and visualization using tools from topology is an active and growing field of Topological Data Analysis (TDA) and data science. Its most prominent line of work is based on the so-called Mapper graph, which is a combinatorial graph whose topological structures (connected components, branches, loops) are in correspondence with those of the data itself. While highly generic and applicable, its use has been hampered so far by the manual tuning of its many parameters-among these, a crucial one is the so-called filter: it is a continuous function whose variations on the data set are the main ingredient for both building the Mapper representation and assessing the presence and sizes of its topological structures. However, while a few parameter tuning methods have already been investigated for the other Mapper parameters (i.e., resolution, gain, clustering), there is currently no method for tuning the filter itself. In this work, we build on a recently proposed optimization framework incorporating topology to provide the first filter optimization scheme for Mapper graphs. In order to achieve this, we propose a relaxed and more general version of the Mapper graph, whose convergence properties are investigated. Finally, we demonstrate the usefulness of our approach by optimizing Mapper graph representations on several datasets, and showcasing the superiority of the optimized representation over arbitrary ones.","Tue, 20 Feb 2024 09:33:22 UTC (2,650 KB)"
"68","Nearly Optimal Fault Tolerant Distance Oracle","Dipan Dey, Manoj Gupta","Data Structures and Algorithms (cs.DS)","We present an $f$-fault tolerant distance oracle for an undirected weighted graph where each edge has an integral weight from $[1 \dots W]$. Given a set $F$ of $f$ edges, as well as a source node $s$ and a destination node $t$, our oracle returns the \emph{shortest path} from $s$ to $t$ avoiding $F$ in $O((cf \log (nW))^{O(f^2)})$ time, where $c > 1$ is a constant. The space complexity of our oracle is $O(f^4n^2\log^2 (nW))$. For a constant $f$, our oracle is nearly optimal both in terms of space and time (barring some logarithmic factor).","Tue, 20 Feb 2024 08:58:37 UTC (85 KB)[v2] Wed, 21 Feb 2024 10:24:10 UTC (96 KB)[v3] Mon, 26 Feb 2024 15:59:24 UTC (97 KB)"
"69","Near-Optimal Quantum Algorithm for Minimizing the Maximal Loss","Hao Wang, Chenyi Zhang, Tongyang Li","Quantum Physics (quant-ph)","The problem of minimizing the maximum of $N$ convex, Lipschitz functions plays significant roles in optimization and machine learning. It has a series of results, with the most recent one requiring $O(N\epsilon^{-2/3} + \epsilon^{-8/3})$ queries to a first-order oracle to compute an $\epsilon$-suboptimal point. On the other hand, quantum algorithms for optimization are rapidly advancing with speedups shown on many important optimization problems. In this paper, we conduct a systematic study for quantum algorithms and lower bounds for minimizing the maximum of $N$ convex, Lipschitz functions. On one hand, we develop quantum algorithms with an improved complexity bound of $\tilde{O}(\sqrt{N}\epsilon^{-5/3} + \epsilon^{-8/3})$. On the other hand, we prove that quantum algorithms must take $\tilde{\Omega}(\sqrt{N}\epsilon^{-2/3})$ queries to a first order quantum oracle, showing that our dependence on $N$ is optimal up to poly-logarithmic factors.","Tue, 20 Feb 2024 06:23:36 UTC (62 KB)"
"70","A Lower Bound on the Competitive Ratio of the Permutation Algorithm for Online Facility Assignment on a Line","Tsubasa Harada","Data Structures and Algorithms (cs.DS)","In the online facility assignment on a line (OFAL) with a set $S$ of $k$ servers and a capacity $c:S\to\mathbb{N}$, each server $s\in S$ with a capacity $c(s)$ is placed on a line and a request arrives on a line one-by-one. The task of an online algorithm is to irrevocably assign a current request to one of the servers with vacancies before the next request arrives. An algorithm can assign up to $c(s)$ requests to each server $s\in S$. In this paper, we show that the competitive ratio of the permutation algorithm is at least $k+1$ for OFAL where the servers are evenly placed on a line. This disproves the result that the permutation algorithm is $k$-competitive by Ahmed et al..","Tue, 20 Feb 2024 05:59:10 UTC (8 KB)[v2] Fri, 23 Feb 2024 01:44:37 UTC (8 KB)"
"71","Controlled Variable Selection from Summary Statistics Only? A Solution via GhostKnockoffs and Penalized Regression","Zhaomeng Chen, Zihuai He, Benjamin B. Chu, Jiaqi Gu, Tim Morrison, Chiara Sabatti, Emmanuel Candès","Methodology (stat.ME)","Identifying which variables do influence a response while controlling false positives pervades statistics and data science. In this paper, we consider a scenario in which we only have access to summary statistics, such as the values of marginal empirical correlations between each dependent variable of potential interest and the response. This situation may arise due to privacy concerns, e.g., to avoid the release of sensitive genetic information. We extend GhostKnockoffs (He et al. [2022]) and introduce variable selection methods based on penalized regression achieving false discovery rate (FDR) control. We report empirical results in extensive simulation studies, demonstrating enhanced performance over previous work. We also apply our methods to genome-wide association studies of Alzheimer's disease, and evidence a significant improvement in power.","Tue, 20 Feb 2024 05:16:24 UTC (6,378 KB)"
"72","Distance Recoloring","Niranka Banerjee, Christian Engels, Duc A. Hoang","Data Structures and Algorithms (cs.DS)","Coloring a graph is a well known problem and used in many different contexts. Here we want to assign $k \geq 1$ colors to each vertex of a graph $G$ such that each edge has two different colors at each endpoint. Such a vertex-coloring, if exists, is called a feasible coloring of $G$. \textsc{Distance Coloring} is an extension to the standard \textsc{Coloring} problem. Here we want to enforce that every pair of distinct vertices of distance less than or equal to $d$ have different colors, for integers $d \geq 1$ and $k \geq d+1$. Reconfiguration problems ask if two given configurations can be transformed into each other with certain rules. For example, the well-known \textsc{Coloring Reconfiguration} asks if there is a way to change one vertex's color at a time, starting from a feasible given coloring $\alpha$ of a graph $G$ to reach another feasible given coloring $\beta$ of $G$, such that all intermediate colorings are also feasible. In this paper, we study the reconfiguration of distance colorings on certain graph classes. We show that even for planar, bipartite, and $2$-degenerate graphs, reconfiguring distance colorings is $\mathsf{PSPACE}$-complete for $d \geq 2$ and $k = \Omega(d^2)$ via a reduction from the well-known \textsc{Sliding Tokens} problem. Additionally, we show that the problem on split graphs remains $\mathsf{PSPACE}$-complete when $d = 2$ and large $k$ but can be solved in polynomial time when $d \geq 3$ and $k \geq d+1$, and design a quadratic-time algorithm to solve the problem on paths for any $d \geq 2$ and $k \geq d+1$.","Tue, 20 Feb 2024 04:09:00 UTC (40 KB)"
"73","Optimal PSPACE-hardness of Approximating Set Cover Reconfiguration","Shuichi Hirahara, Naoto Ohsaka","Computational Complexity (cs.CC)","In the Minmax Set Cover Reconfiguration problem, given a set system $\mathcal{F}$ over a universe and its two covers $\mathcal{C}^\mathsf{start}$ and $\mathcal{C}^\mathsf{goal}$ of size $k$, we wish to transform $\mathcal{C}^\mathsf{start}$ into $\mathcal{C}^\mathsf{goal}$ by repeatedly adding or removing a single set of $\mathcal{F}$ while covering the universe in any intermediate state. Then, the objective is to minimize the maximize size of any intermediate cover during transformation. We prove that Minmax Set Cover Reconfiguration and Minmax Dominating Set Reconfiguration are $\mathsf{PSPACE}$-hard to approximate within a factor of $2-\frac{1}{\operatorname{polyloglog} N}$, where $N$ is the size of the universe and the number of vertices in a graph, respectively, improving upon Ohsaka (SODA 2024) and Karthik C. S. and Manurangsi (2023). This is the first result that exhibits a sharp threshold for the approximation factor of any reconfiguration problem because both problems admit a $2$-factor approximation algorithm as per Ito, Demaine, Harvey, Papadimitriou, Sideri, Uehara, and Uno (Theor. Comput. Sci., 2011). Our proof is based on a reconfiguration analogue of the FGLSS reduction from Probabilistically Checkable Reconfiguration Proofs of Hirahara and Ohsaka (2024). We also prove that for any constant $\varepsilon \in (0,1)$, Minmax Hypergraph Vertex Cover Reconfiguration on $\operatorname{poly}(\varepsilon^{-1})$-uniform hypergraphs is $\mathsf{PSPACE}$-hard to approximate within a factor of $2-\varepsilon$.","Tue, 20 Feb 2024 01:46:30 UTC (29 KB)"
"74","Guarantees on Warm-Started QAOA: Single-Round Approximation Ratios for 3-Regular MAXCUT and Higher-Round Scaling Limits","Reuben Tate, Stephan Eidenbenz","Quantum Physics (quant-ph)","We generalize Farhi et al.'s 0.6924-approximation result technique of the Max-Cut Quantum Approximate Optimization Algorithm (QAOA) on 3-regular graphs to obtain provable lower bounds on the approximation ratio for warm-started QAOA. Given an initialization angle $\theta$, we consider warm-starts where the initial state is a product state where each qubit position is angle $\theta$ away from either the north or south pole of the Bloch sphere; of the two possible qubit positions the position of each qubit is decided by some classically obtained cut encoded as a bitstring $b$. We illustrate through plots how the properties of $b$ and the initialization angle $\theta$ influence the bound on the approximation ratios of warm-started QAOA. We consider various classical algorithms (and the cuts they produce which we use to generate the warm-start). Our results strongly suggest that there does not exist any choice of initialization angle that yields a (worst-case) approximation ratio that simultaneously beats standard QAOA and the classical algorithm used to create the warm-start. Additionally, we show that at $\theta=60^\circ$, warm-started QAOA is able to (effectively) recover the cut used to generate the warm-start, thus suggesting that in practice, this value could be a promising starting angle to explore alternate solutions in a heuristic fashion. Finally, for any combinatorial optimization problem with integer-valued objective values, we provide bounds on the required circuit depth needed for warm-started QAOA to achieve some change in approximation ratio; more specifically, we show that for small $\theta$, the bound is roughly proportional to $1/\theta$.","Tue, 20 Feb 2024 01:22:07 UTC (2,270 KB)"
"75","Lettericity of graphs: an FPT algorithm and a bound on the size of obstructions","Bogdan Alecu, Mamadou Moustapha Kanté, Vadim Lozin, Viktor Zamaraev","Combinatorics (math.CO)","Lettericity is a graph parameter responsible for many attractive structural properties. In particular, graphs of bounded lettericity have bounded linear clique-width and they are well-quasi-ordered by induced subgraphs. The latter property implies that any hereditary class of graphs of bounded lettericity can be described by finitely many forbidden induced subgraphs. This, in turn, implies, in a non-constructive way, polynomial-time recognition of such classes. However, no constructive algorithms and no specific bounds on the size of forbidden graphs are available up to date. In the present paper, we develop an algorithm that recognizes $n$-vertex graphs of lettericity at most $k$ in time $f(k)n^3$ and show that any minimal graph of lettericity more than $k$ has at most $2^{O(k^2\log k)}$ vertices.","Mon, 19 Feb 2024 21:33:01 UTC (27 KB)"
"76","Almost-linear time parameterized algorithm for rankwidth via dynamic rankwidth","Tuukka Korhonen, Marek Sokołowski","Data Structures and Algorithms (cs.DS)","We give an algorithm that given a graph $G$ with $n$ vertices and $m$ edges and an integer $k$, in time $O_k(n^{1+o(1)}) + O(m)$ either outputs a rank decomposition of $G$ of width at most $k$ or determines that the rankwidth of $G$ is larger than $k$; the $O_k(\cdot)$-notation hides factors depending on $k$. Our algorithm returns also a $(2^{k+1}-1)$-expression for cliquewidth, yielding a $(2^{k+1}-1)$-approximation algorithm for cliquewidth with the same running time. This improves upon the $O_k(n^2)$ time algorithm of Fomin and Korhonen [STOC 2022]. The main ingredient of our algorithm is a fully dynamic algorithm for maintaining rank decompositions of bounded width: We give a data structure that for a dynamic $n$-vertex graph $G$ that is updated by edge insertions and deletions maintains a rank decomposition of $G$ of width at most $4k$ under the promise that the rankwidth of $G$ never grows above $k$. The amortized running time of each update is $O_k(2^{\sqrt{\log n} \log \log n})$. The data structure furthermore can maintain whether $G$ satisfies some fixed ${\sf CMSO}_1$ property within the same running time. We also give a framework for performing ``dense'' edge updates inside a given set of vertices $X$, where the new edges inside $X$ are described by a given ${\sf CMSO}_1$ sentence and vertex labels, in amortized $O_k(|X| \cdot 2^{\sqrt{\log n} \log \log n})$ time. Our dynamic algorithm generalizes the dynamic treewidth algorithm of Korhonen, Majewski, Nadara, Pilipczuk, and Sokołowski [FOCS 2023].","Mon, 19 Feb 2024 18:50:53 UTC (489 KB)"
"77","Local certification of forbidden subgraphs","Nicolas Bousquet, Linda Cook, Laurent Feuilloley, Théo Pierron, Sébastien Zeitoun","Distributed, Parallel, and Cluster Computing (cs.DC)","Detecting specific structures in a network has been a very active theme of research in distributed computing for at least a decade. In this paper, we start the study of subgraph detection from the perspective of local certification. Remember that a local certification is a distributed mechanism enabling the nodes of a network to check the correctness of the current configuration, thanks to small pieces of information called certificates. Our main question is: For a given graph $H$, what is the minimum certificate size that allows checking that the network does not contain $H$ as a (possibly induced) subgraph? We show a variety of lower and upper bounds, uncovering an interesting interplay between the optimal certificate size, the size of the forbidden subgraph, and the locality of the verification. Along the way we introduce several new technical tools, in particular what we call the \emph{layered map}, which is not specific to forbidden subgraphs and that we expect to be useful for certifying many other properties.","Mon, 19 Feb 2024 14:01:34 UTC (128 KB)"
"78","Connectivity Labeling in Faulty Colored Graphs","Asaf Petruschka, Shay Sapir, Elad Tzalik","Data Structures and Algorithms (cs.DS)","Fault-tolerant connectivity labelings are schemes that, given an $n$-vertex graph $G=(V,E)$ and $f\geq 1$, produce succinct yet informative labels for the elements of the graph. Given only the labels of two vertices $u,v$ and of the elements in a faulty-set $F$ with $|F|\leq f$, one can determine if $u,v$ are connected in $G-F$, the surviving graph after removing $F$. For the edge or vertex faults models, i.e., $F\subseteq E$ or $F\subseteq V$, a sequence of recent work established schemes with $poly(f,\log n)$-bit labels. This paper considers the color faults model, recently introduced in the context of spanners [Petruschka, Sapir and Tzalik, ITCS'24], which accounts for known correlations between failures. Here, the edges (or vertices) of the input $G$ are arbitrarily colored, and the faulty elements in $F$ are colors; a failing color causes all edges (vertices) of that color to crash. Our main contribution is settling the label length complexity for connectivity under one color fault ($f=1$). The existing implicit solution, by applying the state-of-the-art scheme for edge faults of [Dory and Parter, PODC'21], might yield labels of $\Omega(n)$ bits. We provide a deterministic scheme with labels of $\tilde{O}(\sqrt{n})$ bits in the worst case, and a matching lower bound. Moreover, our scheme is universally optimal: even schemes tailored to handle only colorings of one specific graph topology cannot produce asymptotically smaller labels. We extend our labeling approach to yield a routing scheme avoiding a single forbidden color. We also consider the centralized setting, and show an $\tilde{O}(n)$-space oracle, answering connectivity queries under one color fault in $\tilde{O}(1)$ time. Turning to $f\geq 2$ color faults, we give a randomized labeling scheme with $\tilde{O}(n^{1-1/2^f})$-bit labels, along with a lower bound of $\Omega(n^{1-1/(f+1)})$ bits.","Mon, 19 Feb 2024 13:53:13 UTC (362 KB)"
"79","The Complexity of Geodesic Spanners using Steiner Points","Sarita de Berg, Tim Ophelders, Irene Parada, Frank Staals, Jules Wulms","Computational Geometry (cs.CG)","A geometric $t$-spanner $\mathcal{G}$ on a set $S$ of $n$ point sites in a metric space $P$ is a subgraph of the complete graph on $S$ such that for every pair of sites $p,q$ the distance in $\mathcal{G}$ is a most $t$ times the distance $d(p,q)$ in $P$. We call a connection between two sites in the spanner a link. In some settings, such as when $P$ is a simple polygon with $m$ vertices and a link is a shortest path in $P$, links can consist of $\Theta (m)$ segments and thus have non-constant complexity. The total spanner complexity is a recently-introduced measure of how compact a spanner is. In this paper, we study what happens if we are allowed to introduce $k$ Steiner points to reduce the spanner complexity. We study such Steiner spanners in simple polygons, polygonal domains, and edge-weighted trees. Surprisingly, we show that Steiner points have only limited utility. For a spanner that uses $k$ Steiner points, we provide an $\Omega(nm/k)$ lower bound on the worst-case complexity of any $(3-\varepsilon)$-spanner, and an $\Omega(mn^{1/(t+1)}/k^{1/(t+1)})$ lower bound on the worst-case complexity of any $(t-\varepsilon)$-spanner, for any constant $\varepsilon\in (0,1)$ and integer constant $t \geq 2$. These lower bounds hold in all settings. Additionally, we show NP-hardness for the problem of deciding whether a set of sites in a polygonal domain admits a $3$-spanner with a given maximum complexity using $k$ Steiner points. On the positive side, for trees we show how to build a $2t$-spanner that uses $k$ Steiner points and of complexity $O(mn^{1/t}/k^{1/t} + n \log (n/k))$, for any integer $t \geq 1$. We generalize this result to forests, and apply it to obtain a $2\sqrt{2}t$-spanner in a simple polygon or a $6t$-spanner in a polygonal domain, with total complexity $O(mn^{1/t}(\log k)^{1+1/t}/k^{1/t} + n\log^2 n)$.","Mon, 19 Feb 2024 13:01:46 UTC (872 KB)"
"80","Causal Equal Protection as Algorithmic Fairness","Marcello Di Bello, Nicolò Cangiotti, Michele Loi","Computers and Society (cs.CY)","Over the last ten years the literature in computer science and philosophy has formulated different criteria of algorithmic fairness. One of the most discussed, classification parity, requires that the erroneous classifications of a predictive algorithm occur with equal frequency for groups picked out by protected characteristics. Despite its intuitive appeal, classification parity has come under attack. Multiple scenarios can be imagined in which - intuitively - a predictive algorithm does not treat any individual unfairly, and yet classification parity is violated. To make progress, we turn to a related principle, equal protection, originally developed in the context of criminal justice. Key to equal protection is equalizing the risks of erroneous classifications (in a sense to be specified) as opposed to equalizing the rates of erroneous classifications. We show that equal protection avoids many of the counterexamples to classification parity, but also fails to model our moral intuitions in a number of common scenarios, for example, when the predictor is causally downstream relative to the protected characteristic. To address these difficulties, we defend a novel principle, causal equal protection, that models the fair allocation of the risks of erroneous classification through the lenses of causality.","Mon, 19 Feb 2024 11:30:00 UTC (231 KB)[v2] Tue, 20 Feb 2024 22:53:23 UTC (231 KB)"
"81","Collision-Free Robot Scheduling","Duncan Adamson, Nathan Flaherty, Igor Potapov, Paul Spirakis","Data Structures and Algorithms (cs.DS)","Robots are becoming an increasingly common part of scientific work within laboratory environments. In this paper, we investigate the problem of designing \emph{schedules} for completing a set of tasks at fixed locations with multiple robots in a laboratory. We represent the laboratory as a graph with tasks placed on fixed vertices and robots represented as agents, with the constraint that no two robots may occupy the same vertex at any given timestep. Each schedule is partitioned into a set of timesteps, corresponding to a walk through the graph (allowing for a robot to wait at a vertex to complete a task), with each timestep taking time equal to the time for a robot to move from one vertex to another and each task taking some given number of timesteps during the completion of which a robot must stay at the vertex containing the task. The goal is to determine a set of schedules, with one schedule for each robot, minimising the number of timesteps taken by the schedule taking the greatest number of timesteps within the set of schedules. We show that this problem is NP-complete for many simple classes of graphs, the problem of determining the fastest schedule, defined by the number of time steps required for a robot to visit every vertex in the schedule and complete every task assigned in its assigned schedule. Explicitly, we provide this result for complete graphs, bipartite graphs, star graphs, and planar graphs. Finally, we provide positive results for line graphs, showing that we can find an optimal set of schedules for $k$ robots completing $m$ tasks of equal length of a path of length $n$ in $O(kmn)$ time, and a $k$-approximation when the length of the tasks is unbounded.","Mon, 19 Feb 2024 10:28:34 UTC (232 KB)"
"82","Private Interdependent Valuations: New Bounds for Single-Item Auctions and Matroids","Alon Eden, Michal Feldman, Simon Mauras, Divyarthi Mohan","Computer Science and Game Theory (cs.GT)","We study auction design within the widely acclaimed model of interdependent values, introduced by Milgrom and Weber [1982]. In this model, every bidder $i$ has a private signal $s_i$ for the item for sale, and a public valuation function $v_i(s_1,\ldots,s_n)$ which maps every vector of private signals (of all bidders) into a real value. A recent line of work established the existence of approximately-optimal mechanisms within this framework, even in the more challenging scenario where each bidder's valuation function $v_i$ is also private. This body of work has primarily focused on single-item auctions with two natural classes of valuations: those exhibiting submodularity over signals (SOS) and $d$-critical valuations. In this work we advance the state of the art on interdependent values with private valuation functions, with respect to both SOS and $d$-critical valuations. For SOS valuations, we devise a new mechanism that gives an improved approximation bound of $5$ for single-item auctions. This mechanism employs a novel variant of an ""eating mechanism"", leveraging LP-duality to achieve feasibility with reduced welfare loss. For $d$-critical valuations, we broaden the scope of existing results beyond single-item auctions, introducing a mechanism that gives a $(d+1)$-approximation for any environment with matroid feasibility constraints on the set of agents that can be simultaneously served. Notably, this approximation bound is tight, even with respect to single-item auctions.","Mon, 19 Feb 2024 10:20:21 UTC (27 KB)"
"83","Buffered Streaming Edge Partitioning","Adil Chhabra, Marcelo Fonseca Faraj, Christian Schulz, Daniel Seemaier","Data Structures and Algorithms (cs.DS)","Addressing the challenges of processing massive graphs, which are prevalent in diverse fields such as social, biological, and technical networks, we introduce HeiStreamE and FreightE, two innovative (buffered) streaming algorithms designed for efficient edge partitioning of large-scale graphs. HeiStreamE utilizes an adapted Split-and-Connect graph model and a Fennel-based multilevel partitioning scheme, while FreightE partitions a hypergraph representation of the input graph. Besides ensuring superior solution quality, these approaches also overcome the limitations of existing algorithms by maintaining linear dependency on the graph size in both time and memory complexity with no dependence on the number of blocks of partition. Our comprehensive experimental analysis demonstrates that HeiStreamE outperforms current streaming algorithms and the re-streaming algorithm 2PS in partitioning quality (replication factor), and is more memory-efficient for real-world networks where the number of edges is far greater than the number of vertices. Further, FreightE is shown to produce fast and efficient partitions, particularly for higher numbers of partition blocks.","Mon, 19 Feb 2024 09:26:22 UTC (384 KB)"
"84","To Store or Not to Store: a graph theoretical approach for Dataset Versioning","Anxin Guo, Jingwei Li, Pattara Sukprasert, Samir Khuller, Amol Deshpande, Koyel Mukherjee","Data Structures and Algorithms (cs.DS)","In this work, we study the cost efficient data versioning problem, where the goal is to optimize the storage and reconstruction (retrieval) costs of data versions, given a graph of datasets as nodes and edges capturing edit/delta information. One central variant we study is MinSum Retrieval (MSR) where the goal is to minimize the total retrieval costs, while keeping the storage costs bounded. This problem (along with its variants) was introduced by Bhattacherjee et al. [VLDB'15]. While such problems are frequently encountered in collaborative tools (e.g., version control systems and data analysis pipelines), to the best of our knowledge, no existing research studies the theoretical aspects of these problems. We establish that the currently best-known heuristic, LMG, can perform arbitrarily badly in a simple worst case. Moreover, we show that it is hard to get $o(n)$-approximation for MSR on general graphs even if we relax the storage constraints by an $O(\log n)$ factor. Similar hardness results are shown for other variants. Meanwhile, we propose poly-time approximation schemes for tree-like graphs, motivated by the fact that the graphs arising in practice from typical edit operations are often not arbitrary. As version graphs typically have low treewidth, we further develop new algorithms for bounded treewidth graphs. Furthermore, we propose two new heuristics and evaluate them empirically. First, we extend LMG by considering more potential ``moves'', to propose a new heuristic LMG-All. LMG-All consistently outperforms LMG while having comparable run time on a wide variety of datasets, i.e., version graphs. Secondly, we apply our tree algorithms on the minimum-storage arborescence of an instance, yielding algorithms that are qualitatively better than all previous heuristics for MSR, as well as for another variant BoundedMin Retrieval (BMR).","Sun, 18 Feb 2024 23:57:03 UTC (1,560 KB)"
"85","Faster algorithms on linear delta-matroids","Tomohiro Koana, Magnus Wahlström","Data Structures and Algorithms (cs.DS)","We show new algorithms and constructions over linear delta-matroids. We observe an alternative representation for linear delta-matroids, as a contraction representation over a skew-symmetric matrix. This is equivalent to the more standard ""twist representation"" up to $O(n^\omega)$-time transformations, but is much more convenient for algorithmic tasks. For instance, the problem of finding a max-weight feasible set now reduces directly to the problem of finding a max-weight basis in a linear matroid. Supported by this representation, we provide new algorithms and constructions over linear delta-matroids. We show that the union and delta-sum of linear delta-matroids define linear delta-matroids, and a representation for the resulting delta-matroid can be constructed in randomized time $O(n^\omega)$. Previously, it was only known that these operations define delta-matroids. We also note that every projected linear delta-matroid can be represented as an elementary projection. This implies that several optimization problems over (projected) linear delta-matroids, including the coverage, delta-coverage, and parity problems, reduce (in their decision versions) to a single $O(n^{\omega})$-time matrix rank computation. Using the methods of Harvey, previously used by Cheung, Lao and Leung for linear matroid parity, we furthermore show how to solve the search versions in the same time. This improves on the $O(n^4)$-time augmenting path algorithm of Geelen, Iwata and Murota. Finally, we consider the maximum-cardinality delta-matroid intersection problem. Using Storjohann's algorithms for symbolic determinants, we show that such a solution can be found in $O(n^{\omega+1})$ time. This is the first polynomial-time algorithm for the problem, solving an open question of Kakimura and Takamatsu.","Sun, 18 Feb 2024 14:17:30 UTC (49 KB)"
"86","Odd Cycle Transversal on $P_5$-free Graphs in Polynomial Time","Akanksha Agrawal, Paloma T. Lima, Daniel Lokshtanov, Pawel Rzążewski, Saket Saurabh, Roohani Sharma","Data Structures and Algorithms (cs.DS)","An independent set in a graph G is a set of pairwise non-adjacent vertices. A graph $G$ is bipartite if its vertex set can be partitioned into two independent sets. In the Odd Cycle Transversal problem, the input is a graph $G$ along with a weight function $w$ associating a rational weight with each vertex, and the task is to find a smallest weight vertex subset $S$ in $G$ such that $G - S$ is bipartite; the weight of $S$, $w(S) = \sum_{v\in S} w(v)$. We show that Odd Cycle Transversal is polynomial-time solvable on graphs excluding $P_5$ (a path on five vertices) as an induced subgraph. The problem was previously known to be polynomial-time solvable on $P_4$-free graphs and NP-hard on $P_6$-free graphs [Dabrowski, Feghali, Johnson, Paesani, Paulusma and Rzążewski, Algorithmica 2020]. Bonamy, Dabrowski, Feghali, Johnson and Paulusma [Algorithmica 2019] posed the existence of a polynomial-time algorithm on $P_5$-free graphs as an open problem, this was later re-stated by Rzążewski [Dagstuhl Reports, 9(6): 2019] and by Chudnovsky, King, Pilipczuk, Rzążewski, and Spirkl [SIDMA 2021], who gave an algorithm with running time $n^{O(\sqrt{n})}$.","Sun, 18 Feb 2024 05:42:53 UTC (1,262 KB)"
"87","A Simple Proof that Ricochet Robots is PSPACE-Complete","Jose Balanza-Martinez, Angel A. Cantu, Robert Schweller, Tim Wylie","Computational Complexity (cs.CC)","In this paper, we seek to provide a simpler proof that the relocation problem in Ricochet Robots (Lunar Lockout with fixed geometry) is PSPACE-complete via a reduction from Finite Function Generation (FFG). Although this result was originally proven in 2003, we give a simpler reduction by utilizing the FFG problem, and put the result in context with recent publications showing that relocation is also PSPACE-complete in related models.","Sun, 18 Feb 2024 03:34:44 UTC (732 KB)"
"88","Approximating Partition in Near-Linear Time","Lin Chen, Jiayi Lian, Yuchen Mao, Guochuan Zhang","Data Structures and Algorithms (cs.DS)","We propose an $\widetilde{O}(n + 1/\varepsilon)$-time FPTAS (Fully Polynomial-Time Approximation Scheme) for the classical Partition problem. This is the best possible (up to a logarithmic factor) assuming SETH (Strong Exponential Time Hypothesis) [Abboud, Bringmann, Hermelin, and Shabtay'22]. Prior to our work, the best known FPTAS for Partition runs in $\widetilde{O}(n + 1/\varepsilon^{5/4})$ time [Deng, Jin and Mao'23, Wu and Chen'22]. Our result is obtained by solving a more general problem of weakly approximating Subset Sum.","Sun, 18 Feb 2024 02:18:14 UTC (27 KB)"
"89","An Elementary Predictor Obtaining $2\sqrt{T}$ Distance to Calibration","Eshwar Ram Arunachaleswaran, Natalie Collina, Aaron Roth, Mirah Shi","Machine Learning (cs.LG)","Blasiok et al. [2023] proposed distance to calibration as a natural measure of calibration error that unlike expected calibration error (ECE) is continuous. Recently, Qiao and Zheng [2024] gave a non-constructive argument establishing the existence of an online predictor that can obtain $O(\sqrt{T})$ distance to calibration in the adversarial setting, which is known to be impossible for ECE. They leave as an open problem finding an explicit, efficient algorithm. We resolve this problem and give an extremely simple, efficient, deterministic algorithm that obtains distance to calibration error at most $2\sqrt{T}$.","Sun, 18 Feb 2024 00:53:05 UTC (295 KB)"
"90","Probabilistic Routing for Graph-Based Approximate Nearest Neighbor Search","Kejing Lu, Chuan Xiao, Yoshiharu Ishikawa","Machine Learning (cs.LG)","Approximate nearest neighbor search (ANNS) in high-dimensional spaces is a pivotal challenge in the field of machine learning. In recent years, graph-based methods have emerged as the superior approach to ANNS, establishing a new state of the art. Although various optimizations for graph-based ANNS have been introduced, they predominantly rely on heuristic methods that lack formal theoretical backing. This paper aims to enhance routing within graph-based ANNS by introducing a method that offers a probabilistic guarantee when exploring a node's neighbors in the graph. We formulate the problem as probabilistic routing and develop two baseline strategies by incorporating locality-sensitive techniques. Subsequently, we introduce PEOs, a novel approach that efficiently identifies which neighbors in the graph should be considered for exact distance computation, thus significantly improving efficiency in practice. Our experiments demonstrate that equipping PEOs can increase throughput on a commonly utilized graph index (HNSW) by a factor of 1.6 to 2.5, and its efficiency consistently outperforms the leading-edge routing technique by 1.1 to 1.4 times.","Sat, 17 Feb 2024 18:08:37 UTC (308 KB)"
"91","Treewidth versus clique number. IV. Tree-independence number of graphs excluding an induced star","Clément Dallard, Matjaž Krnc, O-joung Kwon, Martin Milanič, Andrea Munaro, Kenny Štorgel, Sebastian Wiederrecht","Combinatorics (math.CO)","Many recent works address the question of characterizing induced obstructions to bounded treewidth. In 2022, Lozin and Razgon completely answered this question for graph classes defined by finitely many forbidden induced subgraphs. Their result also implies a characterization of graph classes defined by finitely many forbidden induced subgraphs that are $(tw,\omega)$-bounded, that is, treewidth can only be large due to the presence of a large clique. This condition is known to be satisfied for any graph class with bounded tree-independence number, a graph parameter introduced independently by Yolov in 2018 and by Dallard, Milanič, and Štorgel in 2024. Dallard et al. conjectured that $(tw,\omega)$-boundedness is actually equivalent to bounded tree-independence number. We address this conjecture in the context of graph classes defined by finitely many forbidden induced subgraphs and prove it for the case of graph classes excluding an induced star. We also prove it for subclasses of the class of line graphs, determine the exact values of the tree-independence numbers of line graphs of complete graphs and line graphs of complete bipartite graphs, and characterize the tree-independence number of $P_4$-free graphs, which implies a linear-time algorithm for its computation. Applying the algorithmic framework provided in a previous paper of the series leads to polynomial-time algorithms for the Maximum Weight Independent Set problem in an infinite family of graph classes.","Sat, 17 Feb 2024 08:38:58 UTC (33 KB)[v2] Tue, 20 Feb 2024 14:55:58 UTC (33 KB)"
"92","Private PAC Learning May be Harder than Online Learning","Mark Bun, Aloni Cohen, Rathin Desai","Machine Learning (cs.LG)","We continue the study of the computational complexity of differentially private PAC learning and how it is situated within the foundations of machine learning. A recent line of work uncovered a qualitative equivalence between the private PAC model and Littlestone's mistake-bounded model of online learning, in particular, showing that any concept class of Littlestone dimension $d$ can be privately PAC learned using $\mathrm{poly}(d)$ samples. This raises the natural question of whether there might be a generic conversion from online learners to private PAC learners that also preserves computational efficiency. We give a negative answer to this question under reasonable cryptographic assumptions (roughly, those from which it is possible to build indistinguishability obfuscation for all circuits). We exhibit a concept class that admits an online learner running in polynomial time with a polynomial mistake bound, but for which there is no computationally-efficient differentially private PAC learner. Our construction and analysis strengthens and generalizes that of Bun and Zhandry (TCC 2016-A), who established such a separation between private and non-private PAC learner.","Fri, 16 Feb 2024 22:44:52 UTC (107 KB)"
"93","Online Flexible Busy Time Scheduling on Heterogeneous Machines","Gruia Calinescu, Sami Davies, Samir Khuller, Shirley Zhang","Data Structures and Algorithms (cs.DS)","We study the online busy time scheduling model on heterogeneous machines. In our setting, unit-length jobs arrive online with a deadline that is known to the algorithm at the job's arrival time. An algorithm has access to machines, each with different associated capacities and costs. The goal is to schedule jobs on machines before their deadline, so that the total cost incurred by the scheduling algorithm is minimized. Relatively little is known about online busy time scheduling when machines are heterogeneous (i.e., have different costs and capacities), despite this being the most practical model for clients using cloud computing services. We make significant progress in understanding this model by designing an 8-competitive algorithm for the problem on unit-length jobs, and providing a lower bound on the competitive ratio of 2. We further prove that our lower bound is tight in the natural setting when jobs have agreeable deadlines.","Fri, 16 Feb 2024 22:22:39 UTC (992 KB)"
"94","The Competition Complexity of Prophet Inequalities","Johannes Brustle, José Correa, Paul Dütting, Tomer Ezra, Michal Feldman, Victor Verdugo","Computer Science and Game Theory (cs.GT)","We study the classic single-choice prophet inequality problem through a resource augmentation lens. Our goal is to bound the $(1-\varepsilon)$-competition complexity of different types of online algorithms. This metric asks for the smallest $k$ such that the expected value of the online algorithm on $k$ copies of the original instance, is at least a $(1-\varepsilon)$-approximation to the expected offline optimum on a single copy. We show that block threshold algorithms, which set one threshold per copy, are optimal and give a tight bound of $k = \Theta(\log \log 1/\varepsilon)$. This shows that block threshold algorithms approach the offline optimum doubly-exponentially fast. For single threshold algorithms, we give a tight bound of $k = \Theta(\log 1/\varepsilon)$, establishing an exponential gap between block threshold algorithms and single threshold algorithms. Our model and results pave the way for exploring resource-augmented prophet inequalities in combinatorial settings. In line with this, we present preliminary findings for bipartite matching with one-sided vertex arrivals, as well as in XOS combinatorial auctions. Our results have a natural competition complexity interpretation in mechanism design and pricing applications.","Fri, 16 Feb 2024 21:19:04 UTC (38 KB)[v2] Thu, 22 Feb 2024 09:57:06 UTC (38 KB)"
"95","Incremental Topological Ordering and Cycle Detection with Predictions","Samuel McCauley, Benjamin Moseley, Aidin Niaparast, Shikha Singh","Data Structures and Algorithms (cs.DS)","This paper leverages the framework of algorithms-with-predictions to design data structures for two fundamental dynamic graph problems: incremental topological ordering and cycle detection. In these problems, the input is a directed graph on $n$ nodes, and the $m$ edges arrive one by one. The data structure must maintain a topological ordering of the vertices at all times and detect if the newly inserted edge creates a cycle. The theoretically best worst-case algorithms for these problems have high update cost (polynomial in $n$ and $m$). In practice, greedy heuristics (that recompute the solution from scratch each time) perform well but can have high update cost in the worst case. In this paper, we bridge this gap by leveraging predictions to design a learned new data structure for the problems. Our data structure guarantees consistency, robustness, and smoothness with respect to predictions -- that is, it has the best possible running time under perfect predictions, never performs worse than the best-known worst-case methods, and its running time degrades smoothly with the prediction error. Moreover, we demonstrate empirically that predictions, learned from a very small training dataset, are sufficient to provide significant speed-ups on real datasets.","Fri, 16 Feb 2024 19:18:51 UTC (2,613 KB)"
"96","Hypergraph Connectivity Augmentation in Strongly Polynomial Time","Kristóf Bérczi, Karthekeyan Chandrasekaran, Tamás Király, Shubhang Kulkarni","Data Structures and Algorithms (cs.DS)","We consider hypergraph network design problems where the goal is to construct a hypergraph that satisfies certain connectivity requirements. For graph network design problems where the goal is to construct a graph that satisfies certain connectivity requirements, the number of edges in every feasible solution is at most quadratic in the number of vertices. In contrast, for hypergraph network design problems, we might have feasible solutions in which the number of hyperedges is exponential in the number of vertices. This presents an additional technical challenge in hypergraph network design problems compared to graph network design problems: in order to solve the problem in polynomial time, we first need to show that there exists a feasible solution in which the number of hyperedges is polynomial in the input size. The central theme of this work is to show that certain hypergraph network design problems admit solutions in which the number of hyperedges is polynomial in the number of vertices and moreover, can be solved in strongly polynomial time. Our work improves on the previous fastest pseudo-polynomial run-time for these problems. In addition, we develop strongly polynomial time algorithms that return near-uniform hypergraphs as solutions (i.e., every pair of hyperedges differ in size by at most one). As applications of our results, we derive the first strongly polynomial time algorithms for (i) degree-specified hypergraph connectivity augmentation using hyperedges, (ii) degree-specified hypergraph node-to-area connectivity augmentation using hyperedges, and (iii) degree-constrained mixed-hypergraph connectivity augmentation using hyperedges.","Fri, 16 Feb 2024 17:58:58 UTC (219 KB)"
"97","Core Stability in Additively Separable Hedonic Games of Low Treewidth","Tesshu Hanaka, Noleen Köhler, Michael Lampis","Data Structures and Algorithms (cs.DS)","Additively Separable Hedonic Game (ASHG) are coalition-formation games where we are given a graph whose vertices represent $n$ selfish agents and the weight of each edge $uv$ denotes how much agent $u$ gains (or loses) when she is placed in the same coalition as agent $v$. We revisit the computational complexity of the well-known notion of core stability of ASHGs, where the goal is to construct a partition of the agents into coalitions such that no group of agents would prefer to diverge from the given partition and form a new (blocking) coalition. Since both finding a core stable partition and verifying that a given partition is core stable are intractable problems ($\Sigma_2^p$-complete and coNP-complete respectively) we study their complexity from the point of view of structural parameterized complexity, using standard graph-theoretic parameters, such as treewidth.","Fri, 16 Feb 2024 16:39:14 UTC (693 KB)"
"98","Streaming Algorithms for Connectivity Augmentation","Ce Jin, Michael Kapralov, Sepideh Mahabadi, Ali Vakilian","Data Structures and Algorithms (cs.DS)","We study the $k$-connectivity augmentation problem ($k$-CAP) in the single-pass streaming model. Given a $(k-1)$-edge connected graph $G=(V,E)$ that is stored in memory, and a stream of weighted edges $L$ with weights in $\{0,1,\dots,W\}$, the goal is to choose a minimum weight subset $L'\subseteq L$ such that $G'=(V,E\cup L')$ is $k$-edge connected. We give a $(2+\epsilon)$-approximation algorithm for this problem which requires to store $O(\epsilon^{-1} n\log n)$ words. Moreover, we show our result is tight: Any algorithm with better than $2$-approximation for the problem requires $\Omega(n^2)$ bits of space even when $k=2$. This establishes a gap between the optimal approximation factor one can obtain in the streaming vs the offline setting for $k$-CAP. We further consider a natural generalization to the fully streaming model where both $E$ and $L$ arrive in the stream in an arbitrary order. We show that this problem has a space lower bound that matches the best possible size of a spanner of the same approximation ratio. Following this, we give improved results for spanners on weighted graphs: We show a streaming algorithm that finds a $(2t-1+\epsilon)$-approximate weighted spanner of size at most $O(\epsilon^{-1} n^{1+1/t}\log n)$ for integer $t$, whereas the best prior streaming algorithm for spanner on weighted graphs had size depending on $\log W$. Using our spanner result, we provide an optimal $O(t)$-approximation for $k$-CAP in the fully streaming model with $O(nk + n^{1+1/t})$ words of space. Finally we apply our results to network design problems such as Steiner tree augmentation problem (STAP), $k$-edge connected spanning subgraph ($k$-ECSS), and the general Survivable Network Design problem (SNDP). In particular, we show a single-pass $O(t\log k)$-approximation for SNDP using $O(kn^{1+1/t})$ words of space, where $k$ is the maximum connectivity requirement.","Fri, 16 Feb 2024 16:34:08 UTC (236 KB)"
"99","On Permutation Selectors and their Applications in Ad-Hoc Radio Networks Protocols","Jordan Kuschner, Yugarshi Shashwat, Sarthak Yadav, Marek Chrobak","Data Structures and Algorithms (cs.DS)","Selective families of sets, or selectors, are combinatorial tools used to ""isolate"" individual members of sets from some set family. Given a set $X$ and an element $x\in X$, to isolate $x$ from $X$, at least one of the sets in the selector must intersect $X$ on exactly $x$. We study (k,N)-permutation selectors which have the property that they can isolate each element of each $k$-element subset of $\{0,1,...,N-1\}$ in each possible order. These selectors can be used in protocols for ad-hoc radio networks to more efficiently disseminate information along multiple hops. In 2004, Gasieniec, Radzik and Xin gave a construction of a (k,N)-permutation selector of size $O(k^2\log^3 N)$. This paper improves this by providing a probabilistic construction of a (k,N)-permutation selector of size $O(k^2\log N)$. Remarkably, this matches the asymptotic bound for standard strong (k,N)-selectors, that isolate each element of each set of size $k$, but with no restriction on the order. We then show that the use of our (k,N)-permutation selector improves the best running time for gossiping in ad-hoc radio networks by a poly-logarithmic factor.","Fri, 16 Feb 2024 16:05:47 UTC (141 KB)"
"100","Alphabet Reduction for Reconfiguration Problems","Naoto Ohsaka","Computational Complexity (cs.CC)","We present a reconfiguration analogue of alphabet reduction à la Dinur (J. ACM, 2007) and its applications. Given a binary constraint graph $G$ and its two satisfying assignments $\psi^\mathsf{ini}$ and $\psi^\mathsf{tar}$, the Maxmin Binary CSP Reconfiguration problem requests to transform $\psi^\mathsf{ini}$ into $\psi^\mathsf{tar}$ by repeatedly changing the value of a single vertex so that the minimum fraction of satisfied edges is maximized. We demonstrate a polynomial-time reduction from Maxmin Binary CSP Reconfiguration with arbitrarily large alphabet size $W \in \mathbb{N}$ to itself with universal alphabet size $W_0 \in \mathbb{N}$ such that 1. the perfect completeness is preserved, and 2. if any reconfiguration for the former violates $\varepsilon$-fraction of edges, then $\Omega(\varepsilon)$-fraction of edges must be unsatisfied during any reconfiguration for the latter. The crux of its construction is the reconfigurability of Hadamard codes, which enables to reconfigure between a pair of codewords, while avoiding getting too close to the other codewords. Combining this alphabet reduction with gap amplification due to Ohsaka (SODA 2024), we are able to amplify the $1$ vs. $1-\varepsilon$ gap for arbitrarily small $\varepsilon \in (0,1)$ up to the $1$ vs. $1-\varepsilon_0$ for some universal $\varepsilon_0 \in (0,1)$ without blowing up the alphabet size. In particular, a $1$ vs. $1-\varepsilon_0$ gap version of Maxmin Binary CSP Reconfiguration with alphabet size $W_0$ is PSPACE-hard only assuming the Reconfiguration Inapproximability Hypothesis posed by Ohsaka (STACS 2023), whose gap parameter can be arbitrarily small. This may not be achieved only by gap amplification of Ohsaka, which makes the alphabet size gigantic depending on the gap value of the hypothesis.","Fri, 16 Feb 2024 12:26:57 UTC (156 KB)"
"101","Learning-Augmented Skip Lists","Chunkai Fu, Jung Hoon Seo, Samson Zhou","Data Structures and Algorithms (cs.DS)","We study the integration of machine learning advice into the design of skip lists to improve upon traditional data structure design. Given access to a possibly erroneous oracle that outputs estimated fractional frequencies for search queries on a set of items, we construct a skip list that provably provides the optimal expected search time, within nearly a factor of two. In fact, our learning-augmented skip list is still optimal up to a constant factor, even if the oracle is only accurate within a constant factor. We show that if the search queries follow the ubiquitous Zipfian distribution, then the expected search time for an item by our skip list is only a constant, independent of the total number $n$ of items, i.e., $\mathcal{O}(1)$, whereas a traditional skip list will have an expected search time of $\mathcal{O}(\log n)$. We also demonstrate robustness by showing that our data structure achieves an expected search time that is within a constant factor of an oblivious skip list construction even when the predictions are arbitrarily incorrect. Finally, we empirically show that our learning-augmented skip list outperforms traditional skip lists on both synthetic and real-world datasets.","Fri, 16 Feb 2024 05:27:13 UTC (3,927 KB)"
"102","Composition Orderings for Linear Functions and Matrix Multiplication Orderings","Susumu Kubo, Kazuhisa Makino, Souta Sakamoto","Data Structures and Algorithms (cs.DS)","We consider composition orderings for linear functions of one variable. Given $n$ linear functions $f_1,\dots,f_n$ and a constant $c$, the objective is to find a permutation $\sigma$ that minimizes/maximizes $f_{\sigma(n)}\circ\dots\circ f_{\sigma(1)}(c)$. It was first studied in the area of time-dependent scheduling, and known to be solvable in $O(n\log n)$ time if all functions are nondecreasing. In this paper, we present a complete characterization of optimal composition orderings for this case, by regarding linear functions as two-dimensional vectors. We also show several interesting properties on optimal composition orderings such as the equivalence between local and global optimality. Furthermore, by using the characterization above, we provide a fixed-parameter tractable (FPT) algorithm for the composition ordering problem for general linear functions, with respect to the number of decreasing linear functions. We next deal with matrix multiplication orderings as a generalization of composition of linear functions. Given $n$ matrices $M_1,\dots,M_n\in\mathbb{R}^{m\times m}$ and two vectors $w,y\in\mathbb{R}^m$, where $m$ denotes a positive integer, the objective is to find a permutation $\sigma$ that minimizes/maximizes $w^\top M_{\sigma(n)}\dots M_{\sigma(1)} y$. The problem is also viewed as a generalization of flow shop scheduling through a limit. By this extension, we show that the multiplication ordering problem for $2\times 2$ matrices is solvable in $O(n\log n)$ time if all the matrices are simultaneously triangularizable and have nonnegative determinants, and FPT with respect to the number of matrices with negative determinants, if all the matrices are simultaneously triangularizable. As the negative side, we finally prove that three possible natural generalizations are NP-hard: 1) when $m=2$, 2) when $m\geq 3$, and 3) the target version of the problem.","Fri, 16 Feb 2024 04:55:49 UTC (143 KB)"
"103","Collaborative Learning with Different Labeling Functions","Yuyang Deng, Mingda Qiao","Machine Learning (cs.LG)","We study a variant of Collaborative PAC Learning, in which we aim to learn an accurate classifier for each of the $n$ data distributions, while minimizing the number of samples drawn from them in total. Unlike in the usual collaborative learning setup, it is not assumed that there exists a single classifier that is simultaneously accurate for all distributions. We show that, when the data distributions satisfy a weaker realizability assumption, sample-efficient learning is still feasible. We give a learning algorithm based on Empirical Risk Minimization (ERM) on a natural augmentation of the hypothesis class, and the analysis relies on an upper bound on the VC dimension of this augmented class. In terms of the computational efficiency, we show that ERM on the augmented hypothesis class is NP-hard, which gives evidence against the existence of computationally efficient learners in general. On the positive side, for two special cases, we give learners that are both sample- and computationally-efficient.","Fri, 16 Feb 2024 04:32:22 UTC (38 KB)[v2] Tue, 20 Feb 2024 05:14:09 UTC (34 KB)"
"104","Learnability is a Compact Property","Julian Asilis, Siddartha Devic, Shaddin Dughmi, Vatsal Sharan, Shang-Hua Teng","Machine Learning (cs.LG)","Recent work on learning has yielded a striking result: the learnability of various problems can be undecidable, or independent of the standard ZFC axioms of set theory. Furthermore, the learnability of such problems can fail to be a property of finite character: informally, it cannot be detected by examining finite projections of the problem. On the other hand, learning theory abounds with notions of dimension that characterize learning and consider only finite restrictions of the problem, i.e., are properties of finite character. How can these results be reconciled? More precisely, which classes of learning problems are vulnerable to logical undecidability, and which are within the grasp of finite characterizations? We demonstrate that the difficulty of supervised learning with metric losses admits a tight finite characterization. In particular, we prove that the sample complexity of learning a hypothesis class can be detected by examining its finite projections. For realizable and agnostic learning with respect to a wide class of proper loss functions, we demonstrate an exact compactness result: a class is learnable with a given sample complexity precisely when the same is true of all its finite projections. For realizable learning with improper loss functions, we show that exact compactness of sample complexity can fail, and provide matching upper and lower bounds of a factor of 2 on the extent to which such sample complexities can differ. We conjecture that larger gaps are possible for the agnostic case. At the heart of our technical work is a compactness result concerning assignments of variables that maintain a class of functions below a target value, which generalizes Hall's classic matching theorem and may be of independent interest.","Thu, 15 Feb 2024 23:10:45 UTC (53 KB)"
"105","Non-adaptive Bellman-Ford: Yen's improvement is optimal","Jialu Hu, László Kozma","Data Structures and Algorithms (cs.DS)","The Bellman-Ford algorithm for single-source shortest paths repeatedly updates tentative distances in an operation called relaxing an edge. In several important applications a non-adaptive (oblivious) implementation is preferred, which means fixing the entire sequence of relaxations upfront, independent of the edge-weights. In a dense graph on $n$ vertices, the algorithm in its standard form performs $(1 + o(1))n^3$ relaxations. An improvement by Yen from 1970 reduces the number of relaxations by a factor of two. We show that no further constant-factor improvements are possible, and every non-adaptive deterministic algorithm based on relaxations must perform $(\frac{1}{2} - o(1))n^3$ steps. This improves an earlier lower bound of Eppstein of $(\frac{1}{6} - o(1))n^3$. Given that a non-adaptive randomized variant of Bellman-Ford with at most $(\frac{1}{3} + o(1))n^3$ relaxations (with high probability) is known, our result implies a strict separation between deterministic and randomized strategies, answering an open question of Eppstein.","Thu, 15 Feb 2024 22:13:47 UTC (7 KB)"
"106","Correlation Clustering with Vertex Splitting","Matthias Bentert, Alex Crane, Pål Grønås Drange, Felix Reidl, Blair D. Sullivan","Data Structures and Algorithms (cs.DS)","We explore Cluster Editing and its generalization Correlation Clustering with a new operation called permissive vertex splitting which addresses finding overlapping clusters in the face of uncertain information. We determine that both problems are NP-hard, yet they exhibit significant differences in parameterized complexity and approximability. For Cluster Editing with Permissive Vertex Splitting, we show a polynomial kernel when parameterized by the solution size and develop a polynomial-time algorithm with approximation factor 7. In the case of Correlation Clustering, we establish para-NP-hardness when parameterized by solution size and demonstrate that computing an $n^{1-\epsilon}$-approximation is NP-hard for any constant $\epsilon > 0$. Additionally, we extend the established link between Correlation Clustering and Multicut to the setting with permissive vertex splitting.","Thu, 15 Feb 2024 21:45:10 UTC (24 KB)"
"107","Streaming algorithm for balance gain and cost with cardinality constraint on the integer lattice","Jingjing Tan","Data Structures and Algorithms (cs.DS)","Team formation problem is a very important problem in the labor market, and it is proved to be NP-hard. In this paper, we design an efficient bicriteria streaming algorithms to construct a balance between gain and cost in a team formation problem with cardinality constraint on the integer lattice. To solve this problem, we establish a model for maximizing the difference between a nonnegative normalized monotone submodule function and a nonnegative linear function. Further, we discuss the case where the first function of the object function is $\alpha$--weakly submodular. Combining the lattice binary search with the threshold method, we present an online algorithm called bicriteria streaming algorithms. Meanwhile, we give detailed analysis for both of these models.","Thu, 15 Feb 2024 19:57:32 UTC (15 KB)"
"108","Simple, unified analysis of Johnson-Lindenstrauss with applications","Yingru Li","Machine Learning (stat.ML)","In this work, we present a simple and unified analysis of the Johnson-Lindenstrauss (JL) lemma, a cornerstone in the field of dimensionality reduction critical for managing high-dimensional data. Our approach not only simplifies the understanding but also unifies various constructions under the JL framework, including spherical, binary-coin, sparse JL, Gaussian and sub-Gaussian models. This simplification and unification make significant strides in preserving the intrinsic geometry of data, essential across diverse applications from streaming algorithms to reinforcement learning. Notably, we deliver the first rigorous proof of the spherical construction's effectiveness and provide a general class of sub-Gaussian constructions within this simplified framework. At the heart of our contribution is an innovative extension of the Hanson-Wright inequality to high dimensions, complete with explicit constants, marking a substantial leap in the literature. By employing simple yet powerful probabilistic tools and analytical techniques, such as an enhanced diagonalization process, our analysis not only solidifies the JL lemma's theoretical foundation but also extends its practical reach, showcasing its adaptability and importance in contemporary computational algorithms.","Sat, 10 Feb 2024 15:37:46 UTC (30 KB)[v2] Wed, 21 Feb 2024 15:30:52 UTC (37 KB)"
"109","Trainability Barriers in Low-Depth QAOA Landscapes","Joel Rajakumar, John Golden, Andreas Bärtschi, Stephan Eidenbenz","Quantum Physics (quant-ph)","The Quantum Alternating Operator Ansatz (QAOA) is a prominent variational quantum algorithm for solving combinatorial optimization problems. Its effectiveness depends on identifying input parameters that yield high-quality solutions. However, understanding the complexity of training QAOA remains an under-explored area. Previous results have given analytical performance guarantees for a small, fixed number of parameters. At the opposite end of the spectrum, barren plateaus are likely to emerge at $\Omega(n)$ parameters for $n$ qubits. In this work, we study the difficulty of training in the intermediate regime, which is the focus of most current numerical studies and near-term hardware implementations. Through extensive numerical analysis of the quality and quantity of local minima, we argue that QAOA landscapes can exhibit a superpolynomial growth in the number of low-quality local minima even when the number of parameters scales logarithmically with $n$. This means that the common technique of gradient descent from randomly initialized parameters is doomed to fail beyond small $n$, and emphasizes the need for good initial guesses of the optimal parameters.","Thu, 15 Feb 2024 18:45:30 UTC (977 KB)"
"110","Quantum Backtracking in Qrisp Applied to Sudoku Problems","Raphael Seidel, René Zander, Matic Petrič, Niklas Steinmann, David Q. Liu, Nikolay Tcholtchev, Manfred Hauswirth","Quantum Physics (quant-ph)","The quantum backtracking algorithm proposed by Ashley Montanaro raised considerable interest, as it provides a quantum speed-up for a large class of classical optimization algorithms. It does not suffer from Barren-Plateaus and transfers well into the fault-tolerant era, as it requires only a limited number of arbitrary angle gates. Despite its potential, the algorithm has seen limited implementation efforts, presumably due to its abstract formulation. In this work, we provide a detailed instruction on implementing the quantum step operator for arbitrary backtracking instances. For a single controlled diffuser of a binary backtracking tree with depth n, our implementation requires only $6n+14$ CX gates. We detail the process of constructing accept and reject oracles for Sudoku problems using our interface to quantum backtracking. The presented code is written using Qrisp, a high-level quantum programming language, making it executable on most current physical backends and simulators. Subsequently, we perform several simulator based experiments and demonstrate solving 4x4 Sudoku instances with up to 9 empty fields. This is, to the best of our knowledge, the first instance of a compilable implementation of this generality, marking a significant and exciting step forward in quantum software engineering.","Thu, 15 Feb 2024 16:29:44 UTC (343 KB)"
"111","A Piecewise Approach for the Analysis of Exact Algorithms","Katie Clinch, Serge Gaspers, Abdallah Saffidine, Tiankuang Zhang","Data Structures and Algorithms (cs.DS)","To analyze the worst-case running time of branching algorithms, the majority of work in exponential time algorithms focuses on designing complicated branching rules over developing better analysis methods for simple algorithms. In the mid-$2000$s, Fomin et al. [2005] introduced measure & conquer, an advanced general analysis method, sparking widespread adoption for obtaining tighter worst-case running time upper bounds for many fundamental NP-complete problems. Yet, much potential in this direction remains untapped, as most subsequent work applied it without further advancement. Motivated by this, we present piecewise analysis, a new general method that analyzes the running time of branching algorithms. Our approach is to define a similarity ratio that divides instances into groups and then analyze the running time within each group separately. The similarity ratio is a scale between two parameters of an instance I. Instead of relying on a single measure and a single analysis for the whole instance space, our method allows to take advantage of different intrinsic properties of instances with different similarity ratios. To showcase its potential, we reanalyze two $17$-year-old algorithms from Fomin et al. [2007] that solve $4$-Coloring and #$3$-Coloring respectively. The original analysis in their paper gave running times of $O(1.7272^n)$ and $O(1.6262^n)$ respectively for these algorithms, our analysis improves these running times to $O(1.7215^n)$ and $O(1.6232^n)$. Among the two improvements, our new running time $O(1.7215^n)$ is the first improvement in the best known running time for the 4-Coloring problem since 2007.","Thu, 15 Feb 2024 15:28:10 UTC (1,288 KB)"
"112","Parameterized Vertex Integrity Revisited","Tesshu Hanaka, Michael Lampis, Manolis Vasilakis, Kanae Yoshiwatari","Data Structures and Algorithms (cs.DS)","Vertex integrity is a graph parameter that measures the connectivity of a graph. Informally, its meaning is that a graph has small vertex integrity if it has a small separator whose removal disconnects the graph into connected components which are themselves also small. Graphs with low vertex integrity are extremely structured; this renders many hard problems tractable and has recently attracted interest in this notion from the parameterized complexity community. In this paper we revisit the NP-complete problem of computing the vertex integrity of a given graph from the point of view of structural parameterizations. We present a number of new results, which also answer some recently posed open questions from the literature. Specifically: We show that unweighted vertex integrity is W[1]-hard parameterized by treedepth; we show that the problem remains W[1]-hard if we parameterize by feedback edge set size (via a reduction from a Bin Packing variant which may be of independent interest); and complementing this we show that the problem is FPT by max-leaf number. Furthermore, for weighted vertex integrity, we show that the problem admits a single-exponential FPT algorithm parameterized by vertex cover or by modular width, the latter result improving upon a previous algorithm which required weights to be polynomially bounded.","Thu, 15 Feb 2024 14:28:01 UTC (204 KB)"
"113","Parameterized Algorithms for Steiner Forest in Bounded Width Graphs","Andreas Emil Feldmann, Michael Lampis","Data Structures and Algorithms (cs.DS)","In this paper we reassess the parameterized complexity and approximability of the well-studied Steiner Forest problem in several graph classes of bounded width. The problem takes an edge-weighted graph and pairs of vertices as input, and the aim is to find a minimum cost subgraph in which each given vertex pair lies in the same connected component. It is known that this problem is APX-hard in general, and NP-hard on graphs of treewidth 3, treedepth 4, and feedback vertex set size 2. However, Bateni, Hajiaghayi and Marx [JACM, 2011] gave an approximation scheme with a runtime of $n^{O(\frac{k^2}{\varepsilon})}$ on graphs of treewidth $k$. Our main result is a much faster efficient parameterized approximation scheme (EPAS) with a runtime of $2^{O(\frac{k^2}{\varepsilon} \log \frac{k^2}{\varepsilon})} \cdot n^{O(1)}$. If $k$ instead is the vertex cover number of the input graph, we show how to compute the optimum solution in $2^{O(k \log k)} \cdot n^{O(1)}$ time, and we also prove that this runtime dependence on $k$ is asymptotically best possible, under ETH. Furthermore, if $k$ is the size of a feedback edge set, then we obtain a faster $2^{O(k)} \cdot n^{O(1)}$ time algorithm, which again cannot be improved under ETH.","Thu, 15 Feb 2024 09:55:51 UTC (67 KB)"
"114","On the adversarial robustness of Locality-Sensitive Hashing in Hamming space","Michael Kapralov, Mikhail Makarov, Christian Sohler","Data Structures and Algorithms (cs.DS)","Locality-sensitive hashing~[Indyk,Motwani'98] is a classical data structure for approximate nearest neighbor search. It allows, after a close to linear time preprocessing of the input dataset, to find an approximately nearest neighbor of any fixed query in sublinear time in the dataset size. The resulting data structure is randomized and succeeds with high probability for every fixed query. In many modern applications of nearest neighbor search the queries are chosen adaptively. In this paper, we study the robustness of the locality-sensitive hashing to adaptive queries in Hamming space. We present a simple adversary that can, under mild assumptions on the initial point set, provably find a query to the approximate near neighbor search data structure that the data structure fails on. Crucially, our adaptive algorithm finds the hard query exponentially faster than random sampling.","Thu, 15 Feb 2024 04:58:35 UTC (3,735 KB)"
"115","Robust Learning-Augmented Dictionaries","Ali Zeynali, Shahin Kamali, Mohammad Hajiesmaili","Data Structures and Algorithms (cs.DS)","We present the first learning-augmented data structure for implementing dictionaries with optimal consistency and robustness. Our data structure, named RobustSL, is a skip list augmented by predictions of access frequencies of elements in a data sequence. With proper predictions, RobustSL has optimal consistency (achieves static optimality). At the same time, it maintains a logarithmic running time for each operation, ensuring optimal robustness, even if predictions are generated adversarially. Therefore, RobustSL has all the advantages of the recent learning-augmented data structures of Lin, Luo, and Woodruff (ICML 2022) and Cao et al. (arXiv 2023), while providing robustness guarantees that are absent in the previous work. Numerical experiments show that RobustSL outperforms alternative data structures using both synthetic and real datasets.","Thu, 15 Feb 2024 03:45:44 UTC (13,166 KB)"
"116","HyperMagNet: A Magnetic Laplacian based Hypergraph Neural Network","Tatyana Benko, Martin Buck, Ilya Amburg, Stephen J. Young, Sinan G. Aksoy","Machine Learning (cs.LG)","In data science, hypergraphs are natural models for data exhibiting multi-way relations, whereas graphs only capture pairwise. Nonetheless, many proposed hypergraph neural networks effectively reduce hypergraphs to undirected graphs via symmetrized matrix representations, potentially losing important information. We propose an alternative approach to hypergraph neural networks in which the hypergraph is represented as a non-reversible Markov chain. We use this Markov chain to construct a complex Hermitian Laplacian matrix - the magnetic Laplacian - which serves as the input to our proposed hypergraph neural network. We study HyperMagNet for the task of node classification, and demonstrate its effectiveness over graph-reduction based hypergraph neural networks.","Thu, 15 Feb 2024 03:05:45 UTC (300 KB)"
"117","Unbalanced Random Matching Markets with Partial Preferences","Aditya Potukuchi, Shikha Singh","Computer Science and Game Theory (cs.GT)","Properties of stable matchings in the popular random-matching-market model have been studied for over 50 years. In a random matching market, each agent has complete preferences drawn uniformly and independently at random. Wilson (1972), Knuth (1976) and Pittel (1989) proved that in balanced random matching markets, the proposers are matched to their $\ln n$th choice on average. In this paper, we consider markets where agents have partial (truncated) preferences, that is, the proposers only rank their top $d$ partners. Despite the long history of the problem, the following fundamental question remained unanswered: \emph{what is the smallest value of $d$ that results in a perfect stable matching with high probability?} In this paper, we answer this question exactly -- we prove that a degree of $\ln^2 n$ is necessary and sufficient. That is, we show that if $d < (1-\epsilon) \ln^2 n$ then no stable matching is perfect and if $d > (1+ \epsilon) \ln^2 n$, then every stable matching is perfect with high probability. This settles a recent conjecture by Kanoria, Min and Qian (2021). We generalize this threshold for unbalanced markets: we consider a matching market with $n$ agents on the shorter side and $n(\alpha+1)$ agents on the longer side. We show that for markets with $\alpha =o(1)$, the sharp threshold characterizing the existence of perfect stable matching occurs when $d$ is $\ln n \cdot \ln \left(\frac{1 + \alpha}{\alpha + (1/n(\alpha+1))} \right)$. Finally, we extend the line of work studying the effect of imbalance on the expected rank of the proposers (termed the ``stark effect of competition''). We establish the regime in unbalanced markets that forces this stark effect to take shape in markets with partial preferences.","Thu, 15 Feb 2024 02:27:51 UTC (47 KB)"
"118","Fixed-sparsity matrix approximation from matrix-vector products","Noah Amsel, Tyler Chen, Feyza Duman Keles, Diana Halikias, Cameron Musco, Christopher Musco","Data Structures and Algorithms (cs.DS)","We study the problem of approximating a matrix $\mathbf{A}$ with a matrix that has a fixed sparsity pattern (e.g., diagonal, banded, etc.), when $\mathbf{A}$ is accessed only by matrix-vector products. We describe a simple randomized algorithm that returns an approximation with the given sparsity pattern with Frobenius-norm error at most $(1+\varepsilon)$ times the best possible error. When each row of the desired sparsity pattern has at most $s$ nonzero entries, this algorithm requires $O(s/\varepsilon)$ non-adaptive matrix-vector products with $\mathbf{A}$. We also prove a matching lower-bound, showing that, for any sparsity pattern with $\Theta(s)$ nonzeros per row and column, any algorithm achieving $(1+\epsilon)$ approximation requires $\Omega(s/\varepsilon)$ matrix-vector products in the worst case. We thus resolve the matrix-vector product query complexity of the problem up to constant factors, even for the well-studied case of diagonal approximation, for which no previous lower bounds were known.","Wed, 14 Feb 2024 18:25:13 UTC (605 KB)[v2] Thu, 15 Feb 2024 17:18:05 UTC (605 KB)"
"119","A Modern Approach to Electoral Delimitation using the Quadtree Data Structure","Sahil Kale, Gautam Khaire, Jay Patankar, Pujashree Vidap","Data Structures and Algorithms (cs.DS)","The boundaries of electoral constituencies for assembly and parliamentary seats are drafted using a process referred to as delimitation, which ensures fair and equal representation of all citizens. The current delimitation exercise suffers from a number of drawbacks viz. inefficiency, gerrymandering and an uneven seat-to-population ratio, owing to existing legal and constitutional dictates. The existing methods allocate seats to every state but remain silent about their actual shape and location within the state. The main purpose of this research is to study and analyse the performance of existing delimitation algorithms and further propose a potential solution, along with its merits, that involves using a computational model based on the quadtree data structure to automate the districting process by optimizing objective population criteria. The paper presents an approach to electoral delimitation using the quadtree data structure, which is used to partition a two-dimensional geographical space by recursively subdividing it into four quadrants or regions on the basis of population as a parameter value associated with the node. The quadtree makes use of a quadrant schema of the geographical space for representing constituencies, which not only keeps count of the allocated constituencies but also holds their location-specific information. The performance of the proposed algorithm is analysed and evaluated against existing techniques and proves to be an efficient solution in terms of algorithmic complexity and boundary visualisation to the process of political districting.","Wed, 14 Feb 2024 17:32:57 UTC (484 KB)[v2] Fri, 16 Feb 2024 14:24:53 UTC (484 KB)"
"120","Efficient Unitary T-designs from Random Sums","Chi-Fang Chen, Jordan Docter, Michelle Xu, Adam Bouland, Patrick Hayden","Quantum Physics (quant-ph)","Unitary $T$-designs play an important role in quantum information, with diverse applications in quantum algorithms, benchmarking, tomography, and communication. Until now, the most efficient construction of unitary $T$-designs for $n$-qudit systems has been via random local quantum circuits, which have been shown to converge to approximate $T$-designs in the diamond norm using $O(T^{5+o(1)} n^2)$ quantum gates. In this work, we provide a new construction of $T$-designs via random matrix theory using $\tilde{O}(T^2 n^2)$ quantum gates. Our construction leverages two key ideas. First, in the spirit of central limit theorems, we approximate the Gaussian Unitary Ensemble (GUE) by an i.i.d. sum of random Hermitian matrices. Second, we show that the product of just two exponentiated GUE matrices is already approximately Haar random. Thus, multiplying two exponentiated sums over rather simple random matrices yields a unitary $T$-design, via Hamiltonian simulation. A central feature of our proof is a new connection between the polynomial method in quantum query complexity and the large-dimension ($N$) expansion in random matrix theory. In particular, we show that the polynomial method provides exponentially improved bounds on the high moments of certain random matrix ensembles, without requiring intricate Weingarten calculations. In doing so, we define and solve a new type of moment problem on the unit circle, asking whether a finite number of equally weighted points, corresponding to eigenvalues of unitary matrices, can reproduce a given set of moments.","Wed, 14 Feb 2024 17:32:30 UTC (232 KB)"
"121","Iterated Straight-Line Programs","Gonzalo Navarro, Cristian Urbina","Data Structures and Algorithms (cs.DS)","We explore an extension to straight-line programs (SLPs) that outperforms, for some text families, the measure $\delta$ based on substring complexity, a lower bound for most measures and compressors exploiting repetitiveness (which are crucial in areas like Bioinformatics). The extension, called iterated SLPs (ISLPs), allows rules of the form $A \rightarrow \Pi_{i=k_1}^{k_2} B_1^{i^{c_1}}\cdots B_t^{i^{c_t}}$, for which we show how to extract any substring of length $\lambda$, from the represented text $T[1.. n]$, in time $O(\lambda + \log^2 n\log\log n)$. This is the first compressed representation for repetitive texts breaking $\delta$ while, at the same time, supporting direct access to arbitrary text symbols in polylogarithmic time. As a byproduct, we extend Ganardi et al.'s technique to balance any SLP (so it has a derivation tree of logarithmic height) to a wide generalization of SLPs, including ISLPs.","Wed, 14 Feb 2024 15:21:37 UTC (43 KB)[v2] Thu, 15 Feb 2024 09:21:39 UTC (39 KB)"
"122","Better Decremental and Fully Dynamic Sensitivity Oracles for Subgraph Connectivity","Yaowei Long, Yunfan Wang","Data Structures and Algorithms (cs.DS)","We study the \emph{sensitivity oracles problem for subgraph connectivity} in the \emph{decremental} and \emph{fully dynamic} settings. In the fully dynamic setting, we preprocess an $n$-vertices $m$-edges undirected graph $G$ with $n_{\rm off}$ deactivated vertices initially and the others are activated. Then we receive a single update $D\subseteq V(G)$ of size $|D| = d \leq d_{\star}$, representing vertices whose states will be switched. Finally, we get a sequence of queries, each of which asks the connectivity of two given vertices $u$ and $v$ in the activated subgraph. The decremental setting is a special case when there is no deactivated vertex initially, and it is also known as the \emph{vertex-failure connectivity oracles} problem. We present a better deterministic vertex-failure connectivity oracle with $\widehat{O}(d_{\star}m)$ preprocessing time, $\widetilde{O}(m)$ space, $\widetilde{O}(d^{2})$ update time and $O(d)$ query time, which improves the update time of the previous almost-optimal oracle [Long-Saranurak, FOCS 2022] from $\widehat{O}(d^{2})$ to $\widetilde{O}(d^{2})$. We also present a better deterministic fully dynamic sensitivity oracle for subgraph connectivity with $\widehat{O}(\min\{m(n_{\rm off} + d_{\star}),n^{\omega}\})$ preprocessing time, $\widetilde{O}(\min\{m(n_{\rm off} + d_{\star}),n^{2}\})$ space, $\widetilde{O}(d^{2})$ update time and $O(d)$ query time, which significantly improves the update time of the state of the art [Hu-Kosinas-Polak, 2023] from $\widetilde{O}(d^{4})$ to $\widetilde{O}(d^{2})$. Furthermore, our solution is even almost-optimal assuming popular fine-grained complexity conjectures.","Wed, 14 Feb 2024 12:59:43 UTC (32 KB)"
"123","Improved Deterministic Distributed Maximum Weight Independent Set Approximation in Sparse Graphs","Yuval Gil","Data Structures and Algorithms (cs.DS)","We design new deterministic CONGEST approximation algorithms for \emph{maximum weight independent set (MWIS)} in \emph{sparse graphs}. As our main results, we obtain new $\Delta(1+\epsilon)$-approximation algorithms as well as algorithms whose approximation ratio depend strictly on $\alpha$, in graphs with maximum degree $\Delta$ and arboricity $\alpha$. For (deterministic) $\Delta(1+\epsilon)$-approximation, the current state-of-the-art is due to a recent breakthrough by Faour et al.\ [SODA 2023] that showed an $O(\log^{2} (\Delta W)\cdot \log (1/\epsilon)+\log ^{*}n)$-round algorithm, where $W$ is the largest node-weight (this bound translates to $O(\log^{2} n\cdot\log (1/\epsilon))$ under the common assumption that $W=\text{poly}(n)$). As for $\alpha$-dependent approximations, a deterministic CONGEST $(8(1+\epsilon)\cdot\alpha)$-approximation algorithm with runtime $O(\log^{3} n\cdot\log (1/\epsilon))$ can be derived by combining the aforementioned algorithm of Faour et al.\ with a method presented by Kawarabayashi et al.\ [DISC 2020].","Wed, 14 Feb 2024 08:36:52 UTC (22 KB)"
"124","Sequence graphs realizations and ambiguity in language models","Sammy Khalife, Yann Ponty, Laurent Bulteau","Data Structures and Algorithms (cs.DS)","Several popular language models represent local contexts in an input text as bags of words. Such representations are naturally encoded by a sequence graph whose vertices are the distinct words occurring in x, with edges representing the (ordered) co-occurrence of two words within a sliding window of size w. However, this compressed representation is not generally bijective, and may introduce some degree of ambiguity. Some sequence graphs may admit several realizations as a sequence, while others may not admit any realization. In this paper, we study the realizability and ambiguity of sequence graphs from a combinatorial and computational point of view. We consider the existence and enumeration of realizations of a sequence graph under multiple settings: window size w, presence/absence of graph orientation, and presence/absence of weights (multiplicities). When w = 2, we provide polynomial time algorithms for realizability and enumeration in all cases except the undirected/weighted setting, where we show the #P-hardness of enumeration. For a window of size at least 3, we prove hardness of all variants, even when w is considered as a constant, with the notable exception of the undirected/unweighted case for which we propose an XP algorithms for both (realizability and enumeration) problems, tight due to a corresponding W[1]-hardness result. We conclude with an integer program formulation to solve the realizability problem, and with dynamic programming to solve the enumeration problem. This work leaves open the membership to NP for both problems, a non-trivial question due to the existence of minimum realizations having exponential size on the instance encoding.","Tue, 13 Feb 2024 22:22:51 UTC (71 KB)"
"125","Parameterized dynamic data structure for Split Completion","Konrad Majewski, Michał Pilipczuk, Anna Zych-Pawlewicz","Data Structures and Algorithms (cs.DS)","We design a randomized data structure that, for a fully dynamic graph $G$ updated by edge insertions and deletions and integers $k, d$ fixed upon initialization, maintains the answer to the Split Completion problem: whether one can add $k$ edges to $G$ to obtain a split graph. The data structure can be initialized on an edgeless $n$-vertex graph in time $n \cdot (k d \cdot \log n)^{\mathcal{O}(1)}$, and the amortized time complexity of an update is $5^k \cdot (k d \cdot \log n)^{\mathcal{O}(1)}$. The answer provided by the data structure is correct with probability $1-\mathcal{O}(n^{-d})$.","Tue, 13 Feb 2024 21:46:53 UTC (987 KB)"
"126","Deep and shallow data science for multi-scale optical neuroscience","Gal Mishne, Adam Charles","Image and Video Processing (eess.IV)","Optical imaging of the brain has expanded dramatically in the past two decades. New optics, indicators, and experimental paradigms are now enabling in-vivo imaging from the synaptic to the cortex-wide scales. To match the resulting flood of data across scales, computational methods are continuously being developed to meet the need of extracting biologically relevant information. In this pursuit, challenges arise in some domains (e.g., SNR and resolution limits in micron-scale data) that require specialized algorithms. These algorithms can, for example, make use of state-of-the-art machine learning to maximally learn the details of a given scale to optimize the processing pipeline. In contrast, other methods, however, such as graph signal processing, seek to abstract away from some of the details that are scale-specific to provide solutions to specific sub-problems common across scales of neuroimaging. Here we discuss limitations and tradeoffs in algorithmic design with the goal of identifying how data quality and variability can hamper algorithm use and dissemination.","Tue, 13 Feb 2024 21:30:44 UTC (21 KB)"
"127","Almost Tight Bounds for Online Hypergraph Matching","Thorben Tröbst, Rajan Udwani","Data Structures and Algorithms (cs.DS)","In the online hypergraph matching problem, hyperedges of size $k$ over a common ground set arrive online in adversarial order. The goal is to obtain a maximum matching (disjoint set of hyperedges). A naïve greedy algorithm for this problem achieves a competitive ratio of $\frac{1}{k}$. We show that no (randomized) online algorithm has competitive ratio better than $\frac{2+o(1)}{k}$. If edges are allowed to be assigned fractionally, we give a deterministic online algorithm with competitive ratio $\frac{1-o(1)}{\ln(k)}$ and show that no online algorithm can have competitive ratio strictly better than $\frac{1+o(1)}{\ln(k)}$. Lastly, we give a $\frac{1-o(1)}{\ln(k)}$ competitive algorithm for the fractional edge-weighted version of the problem under a free disposal assumption.","Tue, 13 Feb 2024 20:17:24 UTC (34 KB)"
"128","Data Analytics for Intermodal Freight Transportation Applications","Nathan Huynh, Majbah Uddin, Chu Cong Minh","Methodology (stat.ME)","With the growth of intermodal freight transportation, it is important that transportation planners and decision makers are knowledgeable about freight flow data to make informed decisions. This is particularly true with Intelligent Transportation Systems (ITS) offering new capabilities to intermodal freight transportation. Specifically, ITS enables access to multiple different data sources, but they have different formats, resolution, and time scales. Thus, knowledge of data science is essential to be successful in future ITS-enabled intermodal freight transportation system. This chapter discusses the commonly used descriptive and predictive data analytic techniques in intermodal freight transportation applications. These techniques cover the entire spectrum of univariate, bivariate, and multivariate analyses. In addition to illustrating how to apply these techniques through relatively simple examples, this chapter will also show how to apply them using the statistical software R. Additional exercises are provided for those who wish to apply the described techniques to more complex problems.","Tue, 13 Feb 2024 17:41:43 UTC (555 KB)"
"129","Primal-Dual Algorithms with Predictions for Online Bounded Allocation and Ad-Auctions Problems","Eniko Kevi, Nguyen Kim Thang","Data Structures and Algorithms (cs.DS)","Matching problems have been widely studied in the research community, especially Ad-Auctions with many applications ranging from network design to advertising. Following the various advancements in machine learning, one natural question is whether classical algorithms can benefit from machine learning and obtain better-quality solutions. Even a small percentage of performance improvement in matching problems could result in significant gains for the studied use cases. For example, the network throughput or the revenue of Ad-Auctions can increase remarkably. This paper presents algorithms with machine learning predictions for the Online Bounded Allocation and the Online Ad-Auctions problems. We constructed primal-dual algorithms that achieve competitive performance depending on the quality of the predictions. When the predictions are accurate, the algorithms' performance surpasses previous performance bounds, while when the predictions are misleading, the algorithms maintain standard worst-case performance guarantees. We provide supporting experiments on generated data for our theoretical findings.","Tue, 13 Feb 2024 13:02:11 UTC (79 KB)"
"130","Strategizing against No-Regret Learners in First-Price Auctions","Aviad Rubinstein, Junyao Zhao","Computer Science and Game Theory (cs.GT)","We study repeated first-price auctions and general repeated Bayesian games between two players, where one player, the learner, employs a no-regret learning algorithm, and the other player, the optimizer, knowing the learner's algorithm, strategizes to maximize its own utility. For a commonly used class of no-regret learning algorithms called mean-based algorithms, we show that (i) in standard (i.e., full-information) first-price auctions, the optimizer cannot get more than the Stackelberg utility -- a standard benchmark in the literature, but (ii) in Bayesian first-price auctions, there are instances where the optimizer can achieve much higher than the Stackelberg utility. On the other hand, Mansour et al. (2022) showed that a more sophisticated class of algorithms called no-polytope-swap-regret algorithms are sufficient to cap the optimizer's utility at the Stackelberg utility in any repeated Bayesian game (including Bayesian first-price auctions), and they pose the open question whether no-polytope-swap-regret algorithms are necessary to cap the optimizer's utility. For general Bayesian games, under a reasonable and necessary condition, we prove that no-polytope-swap-regret algorithms are indeed necessary to cap the optimizer's utility and thus answer their open question. For Bayesian first-price auctions, we give a simple improvement of the standard algorithm for minimizing the polytope swap regret by exploiting the structure of Bayesian first-price auctions.","Tue, 13 Feb 2024 18:03:56 UTC (37 KB)"
"131","Sampling Space-Saving Set Sketches","Homin K. Lee, Charles Masson","Data Structures and Algorithms (cs.DS)","Large, distributed data streams are now ubiquitous. High-accuracy sketches with low memory overhead have become the de facto method for analyzing this data. For instance, if we wish to group data by some label and report the largest counts using fixed memory, we need to turn to mergeable heavy hitter sketches that can provide highly accurate approximate counts. Similarly, if we wish to keep track of the number of distinct items in a single set spread across several streams using fixed memory, we can turn to mergeable count distinct sketches that can provide highly accurate set cardinalities. If we were to try to keep track of the cardinality of multiple sets and report only on the largest ones, maintaining individual count distinct sketches for each set can grow unwieldy, especially if the number of sets is not known in advance. We consider the natural combination of the heavy hitters problem with the count distinct problem, the heavy distinct hitters problem: given a stream of $(\ell, x)$ pairs, find all the labels $\ell$ that are paired with a large number of distinct items $x$ using only constant memory. No previous work on heavy distinct hitters has managed to be of practical use in the large, distributed data stream setting. We propose a new algorithm, the Sampling Space-Saving Set Sketch, which combines sketching and sampling techniques and has all the desired properties for size, speed, accuracy, mergeability, and invertibility. We compare our algorithm to several existing solutions to the heavy distinct hitters problem, and provide experimental results across several data sets showing the superiority of the new sketch.","Tue, 13 Feb 2024 17:10:58 UTC (86 KB)"
"132","Polynomial-Time Algorithms for Weaver's Discrepancy Problem in a Dense Regime","Ben Jourdan, Peter Macgregor, He Sun","Data Structures and Algorithms (cs.DS)","Given $v_1,\ldots, v_m\in\mathbb{C}^d$ with $\|v_i\|^2= \alpha$ for all $i\in[m]$ as input and suppose $\sum_{i=1}^m | \langle u, v_i \rangle |^2 = 1$ for every unit vector $u\in\mathbb{C}^d$, Weaver's discrepancy problem asks for a partition $S_1, S_2$ of $[m]$, such that $\sum_{i\in S_{j}} |\langle u, v_i \rangle|^2 \leq 1 -\theta$ for some universal constant $\theta$, every unit vector $u\in\mathbb{C}^d$ and every $j\in\{1,2\}$. We prove that this problem can be solved deterministically in polynomial time when $m\geq 49 d^2$.","Tue, 13 Feb 2024 15:50:34 UTC (22 KB)"
"133","Tight (Double) Exponential Bounds for Identification Problems: Locating-Dominating Set and Test Cover","Dipayan Chakraborty, Florent Foucaud, Diptapriyo Majumdar, Prafullkumar Tale","Data Structures and Algorithms (cs.DS)","We investigate fine-grained algorithmic aspects of identification problems in graphs and set systems, with a focus on Locating-Dominating Set and Test Cover. We prove, among other things, the following three (tight) conditional lower bounds. \begin{enumerate} \item \textsc{Locating-Dominating Set} does not admit an algorithm running in time $2^{o(k^2)} \cdot poly(n)$, nor a polynomial time kernelization algorithm that reduces the solution size and outputs a kernel with $2^{o(k)}$ vertices, unless the Ð fails. \end{enumerate} To the best of our knowledge, \textsc{Locating-Dominating Set} is the first problem that admits such an algorithmic lower-bound (with a quadratic function in the exponent) when parameterized by the solution size. \begin{enumerate}[resume] \item \textsc{Test Cover} does not admit an algorithm running in time $2^{2^{o(k)}} \cdot poly(|U| + |\calF|)$. \end{enumerate} After \textsc{Edge Clique Cover} and \textsc{BiClique Cover}, this is the only example that we know of that admits a double exponential lower bound when parameterized by the solution size. \begin{enumerate}[resume] \item \textsc{Locating-Dominating Set} (respectively, \textsc{Test Cover}) parameterized by the treewidth of the input graph (respectively, of the natural auxiliary graph) does not admit an algorithm running in time $2^{2^{o(\tw)}} \cdot poly(n)$ (respectively, $2^{2^{o(\tw)}} \cdot poly(|U| + |\calF|))$. \end{enumerate} This result augments the small list of NP-Complete problems that admit double exponential lower bounds when parameterized by treewidth. We also present algorithms whose running times match the above lower bounds. We also investigate the parameterizations by several other structural graph parameters, answering some open problems from the literature.","Tue, 13 Feb 2024 10:24:20 UTC (5,062 KB)"
"134","Detecting $K_{2,3}$ as an induced minor","Clément Dallard, Maël Dumas, Claire Hilaire, Martin Milanič, Anthony Perez, Nicolas Trotignon","Combinatorics (math.CO)","We consider a natural generalization of chordal graphs, in which every minimal separator induces a subgraph with independence number at most $2$. Such graphs can be equivalently defined as graphs that do not contain the complete bipartite graph $K_{2,3}$ as an induced minor, that is, graphs from which $K_{2,3}$ cannot be obtained by a sequence of edge contractions and vertex deletions. We develop a polynomial-time algorithm for recognizing these graphs. Our algorithm relies on a characterization of $K_{2,3}$-induced minor-free graphs in terms of excluding particular induced subgraphs, called Truemper configurations.","Tue, 13 Feb 2024 09:57:04 UTC (153 KB)"
"135","Integrating High-Dimensional Functions Deterministically","David Gamarnik, Devin Smedira","Data Structures and Algorithms (cs.DS)","We design a Quasi-Polynomial time deterministic approximation algorithm for computing the integral of a multi-dimensional separable function, supported by some underlying hyper-graph structure, appropriately defined. Equivalently, our integral is the partition function of a graphical model with continuous potentials. While randomized algorithms for high-dimensional integration are widely known, deterministic counterparts generally do not exist. We use the correlation decay method applied to the Riemann sum of the function to produce our algorithm. For our method to work, we require that the domain is bounded and the hyper-edge potentials are positive and bounded on the domain. We further assume that upper and lower bounds on the potentials separated by a multiplicative factor of $1 + O(1/\Delta^2)$, where $\Delta$ is the maximum degree of the graph. When $\Delta = 3$, our method works provided the upper and lower bounds are separated by a factor of at most $1.0479$. To the best of our knowledge, our algorithm is the first deterministic algorithm for high-dimensional integration of a continuous function, apart from the case of trivial product form distributions.","Tue, 13 Feb 2024 05:51:43 UTC (119 KB)"
"136","Causal Discovery under Off-Target Interventions","Davin Choo, Kirankumar Shiragur, Caroline Uhler","Machine Learning (cs.LG)","Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a distribution dependent on attempted action. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic competitive ratios and provide some preliminary experimental results.","Tue, 13 Feb 2024 05:43:49 UTC (4,983 KB)"
"137","An Improved Approximation Algorithm for Metric Triangle Packing","Jingyang Zhao, Mingyu Xiao","Data Structures and Algorithms (cs.DS)","Given an edge-weighted metric complete graph with $n$ vertices, the maximum weight metric triangle packing problem is to find a set of $n/3$ vertex-disjoint triangles with the total weight of all triangles in the packing maximized. Several simple methods can lead to a 2/3-approximation ratio. However, this barrier is not easy to break. Chen et al. proposed a randomized approximation algorithm with an expected ratio of $(0.66768-\varepsilon)$ for any constant $\varepsilon>0$. In this paper, we improve the approximation ratio to $(0.66835-\varepsilon)$. Furthermore, we can derandomize our algorithm.","Tue, 13 Feb 2024 05:05:28 UTC (19 KB)"
"138","Detecting Low-Degree Truncation","Anindya De, Huan Li, Shivam Nadimpalli, Rocco A. Servedio","Computational Complexity (cs.CC)","We consider the following basic, and very broad, statistical problem: Given a known high-dimensional distribution ${\cal D}$ over $\mathbb{R}^n$ and a collection of data points in $\mathbb{R}^n$, distinguish between the two possibilities that (i) the data was drawn from ${\cal D}$, versus (ii) the data was drawn from ${\cal D}|_S$, i.e. from ${\cal D}$ subject to truncation by an unknown truncation set $S \subseteq \mathbb{R}^n$. We study this problem in the setting where ${\cal D}$ is a high-dimensional i.i.d. product distribution and $S$ is an unknown degree-$d$ polynomial threshold function (one of the most well-studied types of Boolean-valued function over $\mathbb{R}^n$). Our main results are an efficient algorithm when ${\cal D}$ is a hypercontractive distribution, and a matching lower bound: $\bullet$ For any constant $d$, we give a polynomial-time algorithm which successfully distinguishes ${\cal D}$ from ${\cal D}|_S$ using $O(n^{d/2})$ samples (subject to mild technical conditions on ${\cal D}$ and $S$); $\bullet$ Even for the simplest case of ${\cal D}$ being the uniform distribution over $\{+1, -1\}^n$, we show that for any constant $d$, any distinguishing algorithm for degree-$d$ polynomial threshold functions must use $\Omega(n^{d/2})$ samples.","Mon, 12 Feb 2024 23:59:59 UTC (208 KB)"
"139","Grounding Data Science Code Generation with Input-Output Specifications","Yeming Wen, Pengcheng Yin, Kensen Shi, Henryk Michalewski, Swarat Chaudhuri, Alex Polozov","Machine Learning (cs.LG)","Large language models (LLMs) have recently demonstrated a remarkable ability to generate code from natural language (NL) prompts. However, in the real world, NL is often too ambiguous to capture the true intent behind programming problems, requiring additional input-output (I/O) specifications. Unfortunately, LLMs can have difficulty aligning their outputs with both the NL prompt and the I/O specification. In this paper, we give a way to mitigate this issue in the context of data science programming, where tasks require explicit I/O specifications for clarity. Specifically, we propose GIFT4Code, a novel approach for the instruction fine-tuning of LLMs with respect to I/O specifications. Our method leverages synthetic data produced by the LLM itself and utilizes execution-derived feedback as a key learning signal. This feedback, in the form of program I/O specifications, is provided to the LLM to facilitate instruction fine-tuning. We evaluated our approach on two challenging data science benchmarks, Arcade and DS-1000. The results demonstrate a significant improvement in the LLM's ability to generate code that is not only executable but also accurately aligned with user specifications, substantially improving the quality of code generation for complex data science tasks.","Mon, 12 Feb 2024 21:32:49 UTC (511 KB)"
"140","The Blocklace: A Universal, Byzantine Fault-Tolerant, Conflict-free Replicated Data Type","Paulo Sérgio Almeida, Ehud Shapiro","Distributed, Parallel, and Cluster Computing (cs.DC)","Conflict-free Replicated Data Types (CRDTs) are designed for replica convergence without global coordination or consensus. Recent work has achieves the same in a Byzantine environment, through DAG-like structures based on cryptographic hashes of content. The blocklace is a partially-ordered generalization of the blockchain in which each block has any finite number of signed hash pointers to preceding blocks. We show that the blocklace datatype, with the sole operation of adding a single block, is a CRDT: it is both a pure operation-based CRDT, with self-tagging; and a delta-state CRDT, under a slight generalization of the delta framework. Allowing arbitrary values as payload, the blocklace can also be seen as a universal Byzantine fault-tolerant implementation for arbitrary CRDTs, under the operation-based approach. Current approaches only care about CRDT convergence, being equivocation-tolerant (they do not detect or prevent equivocations), allowing a Byzantine node to cause an arbitrary amount of harm by polluting the CRDT state with an infinite number of equivocations. We show that a blocklace can be used not only in an equivocation-tolerant way, but also so as to detect and eventually exclude Byzantine behavior, namely equivocations, even under the presence of collusion. The blocklace CRDT protocol ensures that the Byzantine nodes may harm only a finite prefix of the computation.","Mon, 12 Feb 2024 21:27:32 UTC (957 KB)[v2] Wed, 14 Feb 2024 14:32:34 UTC (957 KB)[v3] Mon, 26 Feb 2024 15:25:04 UTC (958 KB)"
"141","Tight Algorithm for Connected Odd Cycle Transversal Parameterized by Clique-width","Narek Bojikian, Stefan Kratsch","Data Structures and Algorithms (cs.DS)","Recently, Bojikian and Kratsch [2023] have presented a novel approach to tackle connectivity problems parameterized by clique-width ($\operatorname{cw}$), based on counting small representations of partial solutions (modulo two). Using this technique, they were able to get a tight bound for the Steiner Tree problem, answering an open question posed by Hegerfeld and Kratsch [ESA, 2023]. We use the same technique to solve the Connected Odd Cycle Transversal problem in time $\mathcal{O}^*(12^{\operatorname{cw}})$. We define a new representation of partial solutions by separating the connectivity requirement from the 2-colorability requirement of this problem. Moreover, we prove that our result is tight by providing SETH-based lower bound excluding algorithms with running time $\mathcal{O}^*((12-\epsilon)^{\operatorname{lcw}})$ even when parameterized by linear clique-width. This answers the second question posed by Hegerfeld and Kratsch in the same paper.","Mon, 12 Feb 2024 20:26:19 UTC (70 KB)[v2] Mon, 26 Feb 2024 14:18:56 UTC (72 KB)"
"142","Online Differentially Private Synthetic Data Generation","Yiyun He, Roman Vershynin, Yizhe Zhu","Statistics Theory (math.ST)","We present a polynomial-time algorithm for online differentially private synthetic data generation. For a data stream within the hypercube $[0,1]^d$ and an infinite time horizon, we develop an online algorithm that generates a differentially private synthetic dataset at each time $t$. This algorithm achieves a near-optimal accuracy bound of $O(t^{-1/d}\log(t))$ for $d\geq 2$ and $O(t^{-1}\log^{4.5}(t))$ for $d=1$ in the 1-Wasserstein distance. This result generalizes the previous work on the continual release model for counting queries to include Lipschitz queries. Compared to the offline case, where the entire dataset is available at once, our approach requires only an extra polylog factor in the accuracy bound.","Mon, 12 Feb 2024 19:21:14 UTC (35 KB)"
"143","Educational data mining and learning analytics: An updated survey","C. Romero, S. Ventura","Human-Computer Interaction (cs.HC)","This survey is an updated and improved version of the previous one published in 2013 in this journal with the title data mining in education. It reviews in a comprehensible and very general way how Educational Data Mining and Learning Analytics have been applied over educational data. In the last decade, this research area has evolved enormously and a wide range of related terms are now used in the bibliography such as Academic Analytics, Institutional Analytics, Teaching Analytics, Data-Driven Education, Data-Driven Decision-Making in Education, Big Data in Education, and Educational Data Science. This paper provides the current state of the art by reviewing the main publications, the key milestones, the knowledge discovery cycle, the main educational environments, the specific tools, the free available datasets, the most used methods, the main objectives, and the future trends in this research area.","Sat, 10 Feb 2024 18:48:45 UTC (1,171 KB)"
"144","Factorizing the Brauer monoid in polynomial time","Daniele Marchei, Emanuela Merelli, Andrew Francis","Rings and Algebras (math.RA)","Finding a minimal factorization for a generic semigroup can be done by using the Froidure-Pin Algorithm, which is not feasible for semigroups of large sizes. On the other hand, if we restrict our attention to just a particular semigroup, we could leverage its structure to obtain a much faster algorithm. In particular, $\mathcal{O}(N^2)$ algorithms are known for factorizing the Symmetric group $S_N$ and the Temperley-Lieb monoid $\mathcal{T}\mathcal{L}_N$, but none for their superset the Brauer monoid $\mathcal{B}_{N}$. In this paper we hence propose a $\mathcal{O}(N^4)$ factorization algorithm for $\mathcal{B}_{N}$. At each iteration, the algorithm rewrites the input $X \in \mathcal{B}_{N}$ as $X = X' \circ p_i$ such that $\ell(X') = \ell(X) - 1$, where $p_i$ is a factor for $X$ and $\ell$ is a length function that returns the minimal number of factors needed to generate $X$.","Mon, 12 Feb 2024 18:40:43 UTC (996 KB)[v2] Tue, 13 Feb 2024 10:07:54 UTC (996 KB)"
"145","An approximation algorithm for Maximum DiCut vs. Cut","Tamio-Vesa Nakajima, Stanislav Živný","Data Structures and Algorithms (cs.DS)","Goemans and Williamson designed a 0.878-approximation algorithm for Max-Cut in undirected graphs [JACM'95]. Khot, Kindler, Mosel, and O'Donnel showed that the approximation ratio of the Goemans-Williamson algorithm is optimal assuming Khot's Unique Games Conjecture [SICOMP'07]. In the problem of maximum cuts in directed graphs (Max-DiCut), in which we seek as many edges going from one particular side of the cut to the other, the situation is more complicated but the recent work of Brakensiek, Huang, Potechin, and Zwick showed that their 0.874-approximation algorithm is tight under the Unique Games Conjecture (up to a small delta)[FOCS'23]. We consider a promise version of the problem and design an SDP-based algorithm which, if given a directed graph G that has a directed cut of value rho, finds an undirected cut in G (ignoring edge directions) with value at least \rho.","Mon, 12 Feb 2024 18:17:01 UTC (16 KB)"
"146","On Computationally Efficient Multi-Class Calibration","Parikshit Gopalan, Lunjia Hu, Guy N. Rothblum","Machine Learning (cs.LG)","Consider a multi-class labelling problem, where the labels can take values in $[k]$, and a predictor predicts a distribution over the labels. In this work, we study the following foundational question: Are there notions of multi-class calibration that give strong guarantees of meaningful predictions and can be achieved in time and sample complexities polynomial in $k$? Prior notions of calibration exhibit a tradeoff between computational efficiency and expressivity: they either suffer from having sample complexity exponential in $k$, or needing to solve computationally intractable problems, or give rather weak guarantees. Our main contribution is a notion of calibration that achieves all these desiderata: we formulate a robust notion of projected smooth calibration for multi-class predictions, and give new recalibration algorithms for efficiently calibrating predictors under this definition with complexity polynomial in $k$. Projected smooth calibration gives strong guarantees for all downstream decision makers who want to use the predictor for binary classification problems of the form: does the label belong to a subset $T \subseteq [k]$: e.g. is this an image of an animal? It ensures that the probabilities predicted by summing the probabilities assigned to labels in $T$ are close to some perfectly calibrated binary predictor for that task. We also show that natural strengthenings of our definition are computationally hard to achieve: they run into information theoretic barriers or computational intractability. Underlying both our upper and lower bounds is a tight connection that we prove between multi-class calibration and the well-studied problem of agnostic learning in the (standard) binary prediction setting.","Mon, 12 Feb 2024 17:25:23 UTC (57 KB)"
"147","Quantum walks, the discrete wave equation and Chebyshev polynomials","Simon Apers, Laurent Miclo","Quantum Physics (quant-ph)","A quantum walk is the quantum analogue of a random walk. While it is relatively well understood how quantum walks can speed up random walk hitting times, it is a long-standing open question to what extent quantum walks can speed up the spreading or mixing rate of random walks on graphs. In this expository paper, inspired by a blog post by Terence Tao, we describe a particular perspective on this question that derives quantum walks from the discrete wave equation on graphs. This yields a description of the quantum walk dynamics as simply applying a Chebyshev polynomial to the random walk transition matrix. This perspective decouples the problem from its quantum origin, and highlights connections to earlier (non-quantum) work and the use of Chebyshev polynomials in random walk theory as in the Varopoulos-Carne bound. We illustrate the approach by proving a weak limit of the quantum walk dynamics on the lattice. This gives a different proof of the quadratically improved spreading behavior of quantum walks on lattices.","Mon, 12 Feb 2024 17:15:19 UTC (44 KB)"
"148","Insights into $(k,ρ)$-shortcutting algorithms","Alexander Leonhardt, Ulrich Meyer, Manuel Penschuck","Data Structures and Algorithms (cs.DS)","A graph is called a $(k,\rho)$-graph iff every node can reach $\rho$ of its nearest neighbors in at most k hops. This property proved useful in the analysis and design of parallel shortest-path algorithms. Any graph can be transformed into a $(k,\rho)$-graph by adding shortcuts. Formally, the $(k,\rho)$-Minimum-Shortcut problem asks to find an appropriate shortcut set of minimal cardinality. We show that the $(k,\rho)$-Minimum-Shortcut problem is NP-complete in the practical regime of $k \ge 3$ and $\rho = \Theta(n^\epsilon)$ for $\epsilon > 0$. With a related construction, we bound the approximation factor of known $(k,\rho)$-Minimum-Shortcut problem heuristics from below and propose algorithmic countermeasures improving the approximation quality. Further, we describe an integer linear problem (ILP) solving the $(k,\rho)$-Minimum-Shortcut problem optimally. Finally, we compare the practical performance and quality of all algorithms in an empirical campaign.","Mon, 12 Feb 2024 16:33:23 UTC (1,214 KB)"
"149","Engineering Weighted Connectivity Augmentation Algorithms","Marcelo Fonseca Faraj, Ernestine Großmann, Felix Joos, Thomas Möller, Christian Schulz","Data Structures and Algorithms (cs.DS)","Increasing the connectivity of a graph is a pivotal challenge in robust network design. The weighted connectivity augmentation problem is a common version of the problem that takes link costs into consideration. The problem is then to find a minimum cost subset of a given set of weighted links that increases the connectivity of a graph by one when the links are added to the edge set of the input instance. In this work, we give a first implementation of recently discovered better-than-2 approximations. Furthermore, we propose three new heuristic and one exact approach. These include a greedy algorithm considering link costs and the number of unique cuts covered, an approach based on minimum spanning trees and a local search algorithm that may improve a given solution by swapping links of paths. Our exact approach uses an ILP formulation with efficient cut enumeration as well as a fast initialization routine. We then perform an extensive experimental evaluation which shows that our algorithms are faster and yield the best solutions compared to the current state-of-the-art as well as the recently discovered better-than-2 approximation algorithms. Our novel local search algorithm can improve solution quality even further.","Mon, 12 Feb 2024 16:23:23 UTC (843 KB)"
"150","Pattern Matching with Mismatches and Wildcards","Gabriel Bathie, Panagiotis Charalampopoulos, Tatiana Starikovskaya","Data Structures and Algorithms (cs.DS)","In this work, we address the problem of approximate pattern matching with wildcards. Given a pattern $P$ of length $m$ containing $D$ wildcards, a text $T$ of length $n$, and an integer $k$, our objective is to identify all fragments of $T$ within Hamming distance $k$ from $P$. Our primary contribution is an algorithm with runtime $O(n+(D+k)(G+k)\cdot n/m)$ for this problem. Here, $G \le D$ represents the number of maximal wildcard fragments in $P$. We derive this algorithm by elaborating in a non-trivial way on the ideas presented by [Charalampopoulos et al., FOCS'20] for pattern matching with mismatches (without wildcards). Our algorithm improves over the state of the art when $D$, $G$, and $k$ are small relative to $n$. For instance, if $m = n/2$, $k=G=n^{2/5}$, and $D=n^{3/5}$, our algorithm operates in $O(n)$ time, surpassing the $\Omega(n^{6/5})$ time requirement of all previously known algorithms. In the case of exact pattern matching with wildcards ($k=0$), we present a much simpler algorithm with runtime $O(n+DG\cdot n/m)$ that clearly illustrates our main technical innovation: the utilisation of positions of $P$ that do not belong to any fragment of $P$ with a density of wildcards much larger than $D/m$ as anchors for the sought (approximate) occurrences. Notably, our algorithm outperforms the best-known $O(n\log m)$-time FFT-based algorithms of [Cole and Hariharan, STOC'02] and [Clifford and Clifford, IPL'04] if $DG = o(m\log m)$. We complement our algorithmic results with a structural characterization of the $k$-mismatch occurrences of $P$. We demonstrate that in a text of length $O(m)$, these occurrences can be partitioned into $O((D+k)(G+k))$ arithmetic progressions. Additionally, we construct an infinite family of examples with $\Omega((D+k)k)$ arithmetic progressions of occurrences, leveraging a combinatorial result on progression-free sets [Elkin, SODA'10].","Mon, 12 Feb 2024 15:42:50 UTC (236 KB)"
